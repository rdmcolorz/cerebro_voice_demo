{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import timeit\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.lib.io import file_io\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from random import shuffle\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "from scipy import interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one  two\n",
      "ch1  ch2  ch3  ch4  ch5  ch6  ch7  ch8\n"
     ]
    }
   ],
   "source": [
    "!ls train\n",
    "!ls train/one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set path variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_paths = ['train', 'train_2','train_3']\n",
    "test_path = 'test_data'\n",
    "label_paths = ['one', 'two']\n",
    "channel_paths = ['ch1', 'ch2', 'ch3', 'ch4']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TFR_TRAIN = 'train.tfrecord'\n",
    "TFR_VALID = 'valid.tfrecord'\n",
    "TFR_TEST = 'test.tfrecord'\n",
    "BUCKET = 'gs://robolab/time_test/'\n",
    "\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "IMG_HEIGHT = 80 # four concatenated cropped specs = 4 * 20\n",
    "IMG_WIDTH = 71"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get dictionary of filepaths with corresponding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_list[label] = [ { file_name: file_path_1, file_path_2, ... }, ... ]\n",
    "\n",
    "train_list = defaultdict(list)\n",
    "\n",
    "for path in train_paths:\n",
    "    \n",
    "    for label in label_paths:\n",
    "        \n",
    "        train_dict = defaultdict(list)\n",
    "        \n",
    "        for channel in channel_paths:\n",
    "            \n",
    "            for file in os.listdir(os.path.join(path, label, channel)):\n",
    "                \n",
    "                train_dict[file].append(os.path.join(path, label, channel, file))\n",
    "                \n",
    "        train_list[label].append(train_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log spectogram function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_spectogram(wav,\n",
    "                    sample_rate=8000,\n",
    "                    crop=None,\n",
    "                    nfft=None,\n",
    "                    nperseg=128,\n",
    "                    noverlap=None,\n",
    "                    eps=1e-10,\n",
    "                    spec_only=True):\n",
    "    \n",
    "    freqs, times, spectro = signal.spectrogram(wav,\n",
    "                                               fs=sample_rate,\n",
    "                                               window='hann',\n",
    "                                               noverlap=noverlap,\n",
    "                                               nperseg=nperseg,\n",
    "                                               nfft=None,\n",
    "                                               detrend=False)\n",
    "    \n",
    "    if spec_only:\n",
    "        return np.log(spectro.astype(np.float32) + eps)\n",
    "    else:\n",
    "        return freqs, times, np.log(spectro.astype(np.float32) + eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get 4-channel file lists and corresponding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missind data: 2\n"
     ]
    }
   ],
   "source": [
    "# files = [ [ ch1, ch2, ch3, ch4 ], ... ]\n",
    "# labels = [ label_1, label_2, ... ]\n",
    "\n",
    "files = []\n",
    "labels = []\n",
    "corrupt_files = 0\n",
    "\n",
    "for label in train_list:\n",
    "    \n",
    "    for dictionary in train_list[label]:\n",
    "        \n",
    "        for file_name in dictionary:\n",
    "            \n",
    "            # get list of filepaths and filesizes for all 4 channels\n",
    "            sizes = []\n",
    "            paths = []\n",
    "            \n",
    "            for file_path in dictionary[file_name]:\n",
    "                if 'wav' in file_path:\n",
    "                    fs, wav = wavfile.read(file_path)\n",
    "                    sizes.append(len(wav))\n",
    "                    paths.append(file_path)\n",
    "            \n",
    "            # skip sample list if channel is missing\n",
    "            if len(sizes) == 4:\n",
    "                files.append(paths)\n",
    "                labels.append(label)\n",
    "            else:\n",
    "                corrupt_files += 1\n",
    "                \n",
    "print('Missind data:', corrupt_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle and split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples            4608\n",
      "Train labels             4608\n",
      "Validation samples       512\n",
      "Validation labels        512\n"
     ]
    }
   ],
   "source": [
    "RATIO = 0.9\n",
    "\n",
    "size = round(RATIO * len(files))\n",
    "\n",
    "shuff_files = []\n",
    "shuff_labels = []\n",
    "index_shuf = list(range(len(files)))\n",
    "\n",
    "shuffle(index_shuf)\n",
    "\n",
    "for i in index_shuf:\n",
    "    shuff_files.append(files[i])\n",
    "    shuff_labels.append(labels[i])\n",
    "    \n",
    "train_files = shuff_files[:size]\n",
    "valid_files = shuff_files[size:]\n",
    "\n",
    "train_labels = shuff_labels[:size]\n",
    "valid_labels = shuff_labels[size:]\n",
    "\n",
    "print('{:<25}{}'.format('Train samples', len(train_files)))\n",
    "print('{:<25}{}'.format('Train labels', len(train_labels)))\n",
    "\n",
    "print('{:<25}{}'.format('Validation samples', len(valid_files)))\n",
    "print('{:<25}{}'.format('Validation labels', len(valid_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create train tfrecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# one by one, convert spectograms and enumerated labels to bytes and write them to TF-record file\n",
    "\n",
    "enum_labels = {'one': 0, 'two': 1}\n",
    "\n",
    "writer = tf.python_io.TFRecordWriter(BUCKET + TFR_TRAIN)\n",
    "\n",
    "for files, label in zip(train_files, train_labels):\n",
    "    \n",
    "    cropped_specs = []\n",
    "    \n",
    "    for file in files:\n",
    "\n",
    "        fs, wav = wavfile.read(file)\n",
    "        \n",
    "        # pad if size is not equal to sampling rate = 8000\n",
    "        if len(wav) < fs:\n",
    "        \n",
    "            pad_front = (fs - len(wav)) // 2\n",
    "            pad_end = (fs - len(wav)) - pad_front\n",
    "\n",
    "            wav = np.concatenate(\n",
    "                (np.random.rand(pad_front,) * 10, wav, np.random.rand(pad_end,) * 10), axis=0)\n",
    "        \n",
    "        elif len(wav) > fs:\n",
    "            wav = wav[:fs]\n",
    "        \n",
    "        cropped_specs.append(log_spectogram(wav)[:20,:] / 255)\n",
    "\n",
    "    log_spec = np.concatenate(cropped_specs, axis=0)\n",
    "    np_label = np.asarray([enum_labels[label]], dtype=np.int32)\n",
    "\n",
    "    train_arr_raw = log_spec.tostring()\n",
    "    label_label_raw = np_label.tostring()\n",
    "\n",
    "    example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image_raw': bytes_feature(train_arr_raw),\n",
    "        'label': bytes_feature(label_label_raw)}))\n",
    "\n",
    "    writer.write(example.SerializeToString())\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create validation tfrecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enum_labels = {'one': 0, 'two': 1}\n",
    "\n",
    "writer = tf.python_io.TFRecordWriter(BUCKET + TFR_VALID)\n",
    "\n",
    "for files, label in zip(valid_files, valid_labels):\n",
    "    \n",
    "    cropped_specs = []\n",
    "    \n",
    "    for file in files:\n",
    "\n",
    "        fs, wav = wavfile.read(file)\n",
    "        \n",
    "        # pad if size is not equal to sampling rate\n",
    "        if len(wav) < fs:\n",
    "        \n",
    "            pad_front = (fs - len(wav)) // 2\n",
    "            pad_end = (fs - len(wav)) - pad_front\n",
    "\n",
    "            wav = np.concatenate(\n",
    "                (np.random.rand(pad_front,) * 10, wav, np.random.rand(pad_end,) * 10), axis=0)\n",
    "        \n",
    "        elif len(wav) > fs:\n",
    "            wav = wav[:fs]\n",
    "        \n",
    "        spec = log_spectogram(wav)\n",
    "        cropped_specs.append(spec[:20,:] / 255)\n",
    "\n",
    "    log_spec = np.concatenate(cropped_specs, axis=0)\n",
    "    np_label = np.asarray([enum_labels[label]], dtype=np.int32)\n",
    "\n",
    "    train_arr_raw = log_spec.tostring()\n",
    "    label_label_raw = np_label.tostring()\n",
    "\n",
    "    example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image_raw': bytes_feature(train_arr_raw),\n",
    "        'label': bytes_feature(label_label_raw)}))\n",
    "\n",
    "    writer.write(example.SerializeToString())\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parser(serialized_example):\n",
    "\n",
    "    features = tf.parse_single_example(\n",
    "        serialized_example,\n",
    "        features={\n",
    "            'image_raw': tf.FixedLenFeature([], tf.string),\n",
    "            'label': tf.FixedLenFeature([], tf.string)})\n",
    "\n",
    "    image = tf.decode_raw(features['image_raw'], tf.float32)\n",
    "    image.set_shape([IMG_HEIGHT * IMG_WIDTH])\n",
    "\n",
    "    label = tf.decode_raw(features['label'], tf.int32)\n",
    "    label.set_shape([1])\n",
    "\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_parser(serialized_example):\n",
    "\n",
    "    features = tf.parse_single_example(\n",
    "        serialized_example,\n",
    "        features={'image_raw': tf.FixedLenFeature([], tf.string),\n",
    "                  'image_id': tf.FixedLenFeature([], tf.string)})\n",
    "\n",
    "    image = tf.decode_raw(features['image_raw'], tf.float32)\n",
    "    image.set_shape([IMG_HEIGHT * IMG_WIDTH])\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_input_fn():\n",
    "\n",
    "    # get dataset from tf_record\n",
    "    dataset = tf.data.TFRecordDataset(BUCKET + TFR_TRAIN)\n",
    "\n",
    "    # map parser over dataset samples\n",
    "    dataset = dataset.map(parser)\n",
    "    dataset = dataset.shuffle(1000)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.repeat(1)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "\n",
    "    features, labels = iterator.get_next()\n",
    "\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_input_fn():\n",
    "\n",
    "    # get dataset from tf_record\n",
    "    dataset = tf.data.TFRecordDataset(BUCKET + TFR_TRAIN)\n",
    "\n",
    "    # map parser over dataset samples\n",
    "    dataset = dataset.map(parser)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.repeat(1)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "\n",
    "    features, labels = iterator.get_next()\n",
    "\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def valid_input_fn():\n",
    "\n",
    "    # get dataset from tf_record\n",
    "    dataset = tf.data.TFRecordDataset(BUCKET + TFR_VALID)\n",
    "\n",
    "    # map parser over dataset samples\n",
    "    dataset = dataset.map(parser)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.repeat(1)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "\n",
    "    features, labels = iterator.get_next()\n",
    "\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_input_fn():\n",
    "\n",
    "    # get dataset from tf_record\n",
    "    dataset = tf.data.TFRecordDataset(BUCKET + TFR_TEST)\n",
    "\n",
    "    # map parser over dataset samples\n",
    "    dataset = dataset.map(test_parser)\n",
    "    dataset = dataset.batch(1)\n",
    "    dataset = dataset.repeat(1)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "\n",
    "    features = iterator.get_next()\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cnn_model_fn(features, labels, mode):\n",
    "    \n",
    "    input_layer = tf.reshape(features, [-1, IMG_HEIGHT, IMG_WIDTH], name='inputs')\n",
    "    input_layer = tf.expand_dims(input_layer, axis=3)\n",
    "\n",
    "    conv_layer_1 = tf.layers.conv2d(\n",
    "        inputs=input_layer,\n",
    "        filters=8,\n",
    "        kernel_size=[2, 2],\n",
    "        padding='same',\n",
    "        activation=tf.nn.relu)\n",
    "\n",
    "    pool_layer_1 = tf.layers.max_pooling2d(\n",
    "        inputs=conv_layer_1,\n",
    "        pool_size=[2, 2],\n",
    "        strides=2,\n",
    "        padding='same')\n",
    "\n",
    "    conv_layer_2 = tf.layers.conv2d(\n",
    "        inputs=pool_layer_1,\n",
    "        filters=32,\n",
    "        kernel_size=[2, 2],\n",
    "        padding='same',\n",
    "        activation=tf.nn.relu)\n",
    "\n",
    "    pool_layer_2 = tf.layers.max_pooling2d(\n",
    "        inputs=conv_layer_2,\n",
    "        pool_size=[2, 2],\n",
    "        strides=2,\n",
    "        padding='same')\n",
    "\n",
    "    reshape_layer = tf.layers.flatten(pool_layer_2)\n",
    "\n",
    "    dense_layer = tf.layers.dense(\n",
    "        inputs=reshape_layer,\n",
    "        units=256,\n",
    "        activation=tf.nn.relu)\n",
    "    \n",
    "    is_train = False\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        is_train = True\n",
    "\n",
    "    dropout_layer = tf.layers.dropout(\n",
    "        inputs=dense_layer,\n",
    "        rate=0.2,\n",
    "        training=is_train)\n",
    "\n",
    "    logits_layer = tf.layers.dense(\n",
    "        inputs=dropout_layer,\n",
    "        units=NUM_CLASSES)\n",
    "\n",
    "    predictions = {\n",
    "        'classes':tf.argmax(logits_layer, axis=1),\n",
    "        'probabilities':tf.nn.softmax(logits_layer, axis=1)}\n",
    "\n",
    "    serving_output = tf.estimator.export.ClassificationOutput(scores=predictions['probabilities'])\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode,\n",
    "                                          predictions=predictions,\n",
    "                                          export_outputs={'x':serving_output})\n",
    "\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(\n",
    "        labels=labels,\n",
    "        logits=logits_layer)\n",
    "\n",
    "    accuracy = tf.metrics.accuracy(\n",
    "        labels=labels,\n",
    "        predictions=tf.argmax(logits_layer, axis=1),\n",
    "        name='accu_op')\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        train_optimizer = tf.train.AdamOptimizer(learning_rate=LR).minimize(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_optimizer)\n",
    "\n",
    "    # mode = EVAL\n",
    "    eval_metric_ops = {'accuracy':accuracy}\n",
    "\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate(estimator, epochs=1):\n",
    "\n",
    "    all_train_log = []\n",
    "    all_valid_log = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        estimator.train(input_fn=train_input_fn)\n",
    "\n",
    "        train_log = estimator.evaluate(input_fn=eval_input_fn)\n",
    "        print('epoch: {} of {}'.format(epoch + 1, epochs))\n",
    "        print('train: acc={:.3f}\\tloss={:.3f}'.format(train_log['accuracy'], train_log['loss']))\n",
    "        \n",
    "        valid_log = estimator.evaluate(input_fn=valid_input_fn)\n",
    "        print('valid: acc={:.3f}\\tloss={:.3f}'.format(valid_log['accuracy'], valid_log['loss']))\n",
    "\n",
    "        all_train_log.append(train_log)\n",
    "        all_valid_log.append(valid_log)\n",
    "\n",
    "    return all_train_log, all_valid_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "OUTDIR = BUCKET + 'output'\n",
    "\n",
    "cnn_classifier = tf.estimator.Estimator(model_fn=cnn_model_fn, model_dir=OUTDIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 10\n",
    "EPOCHS = 30\n",
    "LR = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 of 30\n",
      "train: acc=0.835\tloss=0.405\n",
      "valid: acc=0.861\tloss=0.384\n",
      "epoch: 2 of 30\n",
      "train: acc=0.874\tloss=0.296\n",
      "valid: acc=0.883\tloss=0.276\n",
      "epoch: 3 of 30\n",
      "train: acc=0.877\tloss=0.291\n",
      "valid: acc=0.887\tloss=0.279\n",
      "epoch: 4 of 30\n",
      "train: acc=0.887\tloss=0.270\n",
      "valid: acc=0.893\tloss=0.254\n",
      "epoch: 5 of 30\n",
      "train: acc=0.886\tloss=0.260\n",
      "valid: acc=0.887\tloss=0.247\n",
      "epoch: 6 of 30\n",
      "train: acc=0.889\tloss=0.254\n",
      "valid: acc=0.898\tloss=0.239\n",
      "epoch: 7 of 30\n",
      "train: acc=0.892\tloss=0.258\n",
      "valid: acc=0.895\tloss=0.250\n",
      "epoch: 8 of 30\n",
      "train: acc=0.878\tloss=0.269\n",
      "valid: acc=0.875\tloss=0.263\n",
      "epoch: 9 of 30\n",
      "train: acc=0.891\tloss=0.248\n",
      "valid: acc=0.893\tloss=0.245\n",
      "epoch: 10 of 30\n",
      "train: acc=0.896\tloss=0.244\n",
      "valid: acc=0.893\tloss=0.237\n",
      "epoch: 11 of 30\n",
      "train: acc=0.892\tloss=0.240\n",
      "valid: acc=0.889\tloss=0.244\n",
      "epoch: 12 of 30\n",
      "train: acc=0.898\tloss=0.238\n",
      "valid: acc=0.891\tloss=0.242\n",
      "epoch: 13 of 30\n",
      "train: acc=0.860\tloss=0.302\n",
      "valid: acc=0.861\tloss=0.301\n",
      "epoch: 14 of 30\n",
      "train: acc=0.905\tloss=0.222\n",
      "valid: acc=0.902\tloss=0.232\n",
      "epoch: 15 of 30\n",
      "train: acc=0.904\tloss=0.216\n",
      "valid: acc=0.902\tloss=0.228\n",
      "epoch: 16 of 30\n",
      "train: acc=0.898\tloss=0.224\n",
      "valid: acc=0.900\tloss=0.245\n",
      "epoch: 17 of 30\n",
      "train: acc=0.913\tloss=0.203\n",
      "valid: acc=0.912\tloss=0.222\n",
      "epoch: 18 of 30\n",
      "train: acc=0.915\tloss=0.199\n",
      "valid: acc=0.900\tloss=0.221\n",
      "epoch: 19 of 30\n",
      "train: acc=0.909\tloss=0.205\n",
      "valid: acc=0.895\tloss=0.235\n",
      "epoch: 20 of 30\n",
      "train: acc=0.914\tloss=0.197\n",
      "valid: acc=0.910\tloss=0.226\n",
      "epoch: 21 of 30\n",
      "train: acc=0.918\tloss=0.196\n",
      "valid: acc=0.910\tloss=0.223\n",
      "epoch: 22 of 30\n",
      "train: acc=0.927\tloss=0.181\n",
      "valid: acc=0.912\tloss=0.217\n",
      "epoch: 23 of 30\n",
      "train: acc=0.909\tloss=0.203\n",
      "valid: acc=0.900\tloss=0.242\n",
      "epoch: 24 of 30\n",
      "train: acc=0.929\tloss=0.176\n",
      "valid: acc=0.918\tloss=0.215\n",
      "epoch: 25 of 30\n",
      "train: acc=0.929\tloss=0.168\n",
      "valid: acc=0.916\tloss=0.218\n",
      "epoch: 26 of 30\n",
      "train: acc=0.924\tloss=0.176\n",
      "valid: acc=0.912\tloss=0.217\n",
      "epoch: 27 of 30\n",
      "train: acc=0.930\tloss=0.169\n",
      "valid: acc=0.910\tloss=0.221\n",
      "epoch: 28 of 30\n",
      "train: acc=0.932\tloss=0.171\n",
      "valid: acc=0.924\tloss=0.219\n",
      "epoch: 29 of 30\n",
      "train: acc=0.923\tloss=0.177\n",
      "valid: acc=0.900\tloss=0.246\n",
      "epoch: 30 of 30\n",
      "train: acc=0.934\tloss=0.156\n",
      "valid: acc=0.916\tloss=0.215\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "\n",
    "train_log, valid_log = train_and_evaluate(cnn_classifier, epochs=EPOCHS)\n",
    "\n",
    "end = timeit.default_timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current machine: 8 CPUs, 30 Gb memory, no GPUs\n",
      "Time spent: 14 min\n"
     ]
    }
   ],
   "source": [
    "print('Time spent:', round((end - start) / 60) , 'min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_files = defaultdict(list)\n",
    "\n",
    "for folder in os.listdir(test_path):\n",
    "    for file in os.listdir(os.path.join(test_path, folder)):\n",
    "        test_files[folder].append(os.path.join(test_path, folder, file))\n",
    "    test_files[folder].sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test_data/6WH2MEKA/ch1.wav',\n",
       " 'test_data/6WH2MEKA/ch2.wav',\n",
       " 'test_data/6WH2MEKA/ch3.wav',\n",
       " 'test_data/6WH2MEKA/ch4.wav']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_files['6WH2MEKA']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create test tfrecord file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "secret_labels = []\n",
    "\n",
    "writer = tf.python_io.TFRecordWriter(BUCKET + TFR_TEST)\n",
    "\n",
    "for folder in test_files:\n",
    "    \n",
    "    cropped_specs = []\n",
    "    \n",
    "    for file in test_files[folder]:\n",
    "\n",
    "        fs, wav = wavfile.read(file)\n",
    "        \n",
    "        # pad if size is not equal to sampling rate\n",
    "        if len(wav) < fs:\n",
    "        \n",
    "            pad_front = (fs - len(wav)) // 2\n",
    "            pad_end = (fs - len(wav)) - pad_front\n",
    "\n",
    "            wav = np.concatenate(\n",
    "                (np.random.rand(pad_front,) * 10, wav, np.random.rand(pad_end,) * 10), axis=0)\n",
    "        \n",
    "        elif len(wav) > fs:\n",
    "            wav = wav[:fs]\n",
    "        \n",
    "        cropped_specs.append(log_spectogram(wav)[:20,:] / 255)\n",
    "\n",
    "    log_spec = np.concatenate(cropped_specs, axis=0)\n",
    "    secret_labels.append(folder)\n",
    "    \n",
    "    secret_label_raw = bytes(folder, 'utf-8')\n",
    "    test_arr_raw = log_spec.tostring()\n",
    "\n",
    "    example = tf.train.Example(features=tf.train.Features(\n",
    "        feature={'image_raw': bytes_feature(test_arr_raw),\n",
    "                 'image_id': bytes_feature(secret_label_raw)}))\n",
    "\n",
    "    writer.write(example.SerializeToString())\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent: 0 min\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "\n",
    "predict_generator = cnn_classifier.predict(input_fn=predict_input_fn)\n",
    "\n",
    "preds = []\n",
    "predict_dictlist = []\n",
    "\n",
    "while True:\n",
    "    item = next(predict_generator, None)\n",
    "    if item == None:\n",
    "        break\n",
    "    predict_dictlist.append(item)\n",
    "\n",
    "for i in range(len(predict_dictlist)):\n",
    "    \n",
    "    class_ = predict_dictlist[i]['classes']\n",
    "    preds.append(class_)\n",
    "\n",
    "end = timeit.default_timer()\n",
    "\n",
    "print('Time spent:', round((end - start) / 60) , 'min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write submission file to gs bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_filename = 'submission.csv'\n",
    "submission_filepath = os.path.join(BUCKET, 'subs', sub_filename)\n",
    "\n",
    "preds = [i + 1 for i in preds]\n",
    "\n",
    "with file_io.FileIO(submission_filepath, mode='w') as fout:\n",
    "    fout.write('filename,label\\n')\n",
    "    for pred, secret_label in zip(preds, secret_labels):\n",
    "        fout.write('{},{}\\n'.format(secret_label, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy submission folder from gs bucket to local dir if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://robolab/subs/submission.csv...\n",
      "/ [1 files][ 10.8 KiB/ 10.8 KiB]                                                \n",
      "Operation completed over 1 objects/10.8 KiB.                                     \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp -r gs://robolab/subs ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
