{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\n",
      "compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import IPython.display as ipd\n",
    "import random\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as py\n",
    "from IPython import display\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import subprocess\n",
    "%matplotlib inline\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "# NOTES\n",
    "NOTES = \"28x28\"\n",
    "\n",
    "# VARS\n",
    "target_label = \"Label\"\n",
    "id_label = \"fname\"\n",
    "VERBOSE = True\n",
    "DISPLAY = True\n",
    "TEST = False\n",
    "TPU = False\n",
    "RESIZE = True\n",
    "INPUT_WIDTH = 128\n",
    "INPUT_HEIGHT = 128\n",
    "TARGET_WIDTH = 28 if RESIZE else INPUT_WIDTH\n",
    "TARGET_HEIGHT = 28 if RESIZE else INPUT_HEIGHT\n",
    "DECAY_RATE = 0.9\n",
    "IMG_CHANNELS = 3\n",
    "DROPOUT = 0.4\n",
    "TYPE = \"CNN\"\n",
    "DEFAULT_BS = 128 # default batch size\n",
    "UNK_DROP_RATE = 1.0 # drop 100% of unknown categories\n",
    "OUTLIER_PERCENTAGE = 0.1\n",
    "\n",
    "CATEGORY = [\"no_voice\"]\n",
    "LABELS = [\"one\", \"two\"]\n",
    "CHANNELS = [1, 2, 3, 4]\n",
    "NUMS = ''.join([str(x) for x in CHANNELS])\n",
    "MONTHS = [11]\n",
    "DAYS = [14]\n",
    "\n",
    "if TEST:\n",
    "    LEARNING_STEPS = 100\n",
    "    SPP = 4\n",
    "    LEARNING_RATE = .05\n",
    "    BATCH_SIZE = 32\n",
    "    VERBOSITY = 1000\n",
    "    TEST_SIZE = 1000\n",
    "    SHUFFLE_SIZE = 64\n",
    "else:\n",
    "    LEARNING_STEPS = 5000\n",
    "    SPP = 200\n",
    "    LEARNING_RATE = .025\n",
    "    BATCH_SIZE = 64\n",
    "    VERBOSITY = 1000\n",
    "    SHUFFLE_SIZE = 256\n",
    "\n",
    "def curr_time():\n",
    "    return datetime.now() - timedelta(hours=7) # offset from UTC to PST\n",
    "\n",
    "ROOT = os.getcwd() + \"/\"\n",
    "if CATEGORY[0] == \"no_voice\":\n",
    "    RUN_ROOT = ROOT+\"NONVOCAL_RUNS_YN_{:02}_{:02}/\".format(MONTHS[0], DAYS[0])\n",
    "else:\n",
    "    RUN_ROOT = ROOT+\"VOCAL_RUNS_YN_{:02}_{:02}/\".format(MONTHS[0], DAYS[0])\n",
    "RUN_ROOT_LOG = RUN_ROOT+\"logs/\"\n",
    "\n",
    "# PATHS\n",
    "paths = {\n",
    "    \"Training\":ROOT+\"taylor_11_14.csv\",\n",
    "    \"Model\":RUN_ROOT+\"model_dir_{}/\".format(NUMS),\n",
    "    \"Logs\":RUN_ROOT_LOG+\"{}_{}/\".format(NUMS, datetime.strftime(curr_time(), \"%b%d%Y_%H%M%S\"))\n",
    "}\n",
    "paths[\"Log\"] = paths[\"Logs\"] + \"log.txt\"\n",
    "if not os.path.isdir(RUN_ROOT):\n",
    "    os.mkdir(RUN_ROOT)\n",
    "if not os.path.isdir(RUN_ROOT_LOG):\n",
    "    os.mkdir(RUN_ROOT_LOG)\n",
    "if not os.path.isdir(paths[\"Logs\"]):\n",
    "    os.mkdir(paths[\"Logs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_header(s):\n",
    "    return (\"#\" * 42) + (\"\\n{:^42}\\n\".format(s)) + (\"#\" * 42)\n",
    "    \n",
    "def print_and_log(s):\n",
    "    with open(paths[\"Log\"], 'a') as log:\n",
    "        log.write(str(s))\n",
    "        log.write(\"\\n\")\n",
    "    print(s)\n",
    "        \n",
    "def print_and_log_header(s):\n",
    "    h = make_header(str(s))\n",
    "    with open(paths[\"Log\"], 'a') as log:\n",
    "        log.write(h)\n",
    "        log.write(\"\\n\")\n",
    "    print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sec_to_str(secs):\n",
    "    ms = secs - int(secs)\n",
    "    days = int(secs // (24 * 3600))\n",
    "    hours = int((secs % ((24 * 3600))) // 3600)\n",
    "    minutes = int((secs % 3600) // 60)\n",
    "    seconds = int(secs % 60)\n",
    "    return \"{:02}:{:02}:{:02}:{:02}.{}\".format(days, hours, minutes, seconds, \"{:.3}\".format(ms)[2:])\n",
    "\n",
    "def timer(f, *args):\n",
    "    print_and_log(\"Start: {}\".format(curr_time()))\n",
    "    start = time.time()\n",
    "    result = f(*args)\n",
    "    end = time.time()\n",
    "    print_and_log(\"End: {}\".format(curr_time()))\n",
    "    print_and_log(\"Finished in {}\".format(sec_to_str(end - start)))\n",
    "    return result\n",
    "\n",
    "def preprocess(samples, sample_rate):\n",
    "    padded = np.zeros(sample_rate)\n",
    "    samples = samples[:sample_rate]\n",
    "    padded[:samples.shape[0]] = samples\n",
    "    return padded\n",
    "\n",
    "def select_labels(df, allowed):\n",
    "    return df[df['Label'].isin(allowed)]\n",
    "    \n",
    "def select_categories(df, allowed):\n",
    "    return df[df['Category'].isin(allowed)]\n",
    "\n",
    "def select_channels(df, allowed):\n",
    "    labels = []\n",
    "    for i in range(1, 9):\n",
    "        if i not in allowed:\n",
    "            labels.append(\"Path{}\".format(i))\n",
    "    return df.drop(labels, axis=1)\n",
    "\n",
    "def select_days(df, allowed):\n",
    "    return df[df['Day'].isin(allowed)]\n",
    "\n",
    "def select_months(df, allowed):\n",
    "    return df[df['Month'].isin(allowed)]\n",
    "\n",
    "def select_sets(df, allowed):\n",
    "    return df[df['Set'].isin(allowed)]\n",
    "\n",
    "def remove_voice(df):\n",
    "    return df.drop([\"Path4\"], axis=1)\n",
    "\n",
    "def str_to_l(x):\n",
    "    return [int(n) for n in x if n <= '9' and n >= '0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "def _parse_function(label, *filenames):\n",
    "    global count\n",
    "    count += 1\n",
    "    if count % VERBOSITY == 0:\n",
    "        print_and_log(\"\\tProcessed {}th image\".format(count))\n",
    "    expected_shape = tf.constant([1, INPUT_HEIGHT, INPUT_WIDTH, IMG_CHANNELS])\n",
    "    image = None\n",
    "    for filename in filenames:\n",
    "        image_string = tf.read_file(filename)\n",
    "        image_decoded = tf.image.decode_image(image_string, channels=IMG_CHANNELS)\n",
    "        image_decoded = tf.image.convert_image_dtype(image_decoded, tf.float32)\n",
    "        image_decoded = tf.reshape(image_decoded, expected_shape)\n",
    "        image_decoded = tf.image.rgb_to_grayscale(image_decoded)\n",
    "        if RESIZE:\n",
    "            image_decoded = tf.image.resize_bicubic(image_decoded, [TARGET_HEIGHT, TARGET_WIDTH])\n",
    "        if image is not None:\n",
    "            image = tf.concat([image, image_decoded], 3)\n",
    "        else:\n",
    "            image = image_decoded\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode):\n",
    "    input_layer = tf.reshape(features, [-1, TARGET_HEIGHT, TARGET_WIDTH, len(CHANNELS)])\n",
    "    pool = input_layer\n",
    "\n",
    "    for num_filters in [32, 64]:\n",
    "        conv = tf.layers.conv2d(\n",
    "            inputs=pool,\n",
    "            filters=num_filters,\n",
    "            kernel_size=[5, 5],\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu)\n",
    "        pool = tf.layers.max_pooling2d(inputs=conv, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    # Dense Layer\n",
    "    pool = tf.layers.flatten(pool)\n",
    "    dense = tf.layers.dense(inputs=pool, units=1024, activation=tf.nn.relu)\n",
    "    dropout = tf.layers.dropout(inputs=dense, rate=DROPOUT, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "    # Logits Layer\n",
    "    logits = tf.layers.dense(inputs=dropout, units=num_labels)\n",
    "    \n",
    "    predictions = {\n",
    "        \"classes\": tf.argmax(input=logits, axis=1),\n",
    "        \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "    }\n",
    "    if not TPU:\n",
    "        tf.summary.histogram(\"predictions\", predictions[\"probabilities\"])\n",
    "        tf.summary.histogram(\"classes\", predictions[\"classes\"])\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "    learning_rate = tf.train.exponential_decay(LEARNING_RATE, tf.train.get_global_step(), SPP, DECAY_RATE, staircase=True)\n",
    "    \n",
    "    # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "    predictions[\"loss\"] = loss\n",
    "    \n",
    "    # Configure the Training Op (for TRAIN mode)\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "        if TPU:\n",
    "            optimizer = tf.contrib.tpu.CrossShardOptimizer(optimizer)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "    # Add evaluation metrics (for EVAL mode)\n",
    "    eval_metric_ops = {\n",
    "        \"accuracy\": tf.metrics.accuracy(\n",
    "            labels=labels, predictions=predictions[\"classes\"])}\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_training_input_fn(dataset, batch_size, num_epochs=None):\n",
    "    def _input_fn(num_epochs=None, shuffle=True):\n",
    "        ds = dataset.batch(batch_size).repeat(num_epochs)\n",
    "        if shuffle:\n",
    "            ds = ds.shuffle(SHUFFLE_SIZE)\n",
    "        feature_batch, label_batch = ds.make_one_shot_iterator().get_next()\n",
    "        return feature_batch, label_batch\n",
    "    return _input_fn\n",
    "\n",
    "def create_predict_input_fn(dataset, batch_size):\n",
    "    def _input_fn():\n",
    "        ds = dataset.batch(batch_size)\n",
    "        feature_batch, label_batch = ds.make_one_shot_iterator().get_next()\n",
    "        return feature_batch, label_batch\n",
    "    return _input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(paths[\"Log\"], 'w') as log:\n",
    "    log.write(make_header(\"Starting Script\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create variables for the paths\n",
    "train_csv = paths[\"Training\"]\n",
    "\n",
    "# Store the labels to train\n",
    "all_labels = LABELS\n",
    "labels = [\"one\", \"two\"]\n",
    "num_labels = len(labels)\n",
    "labels = {x[1]:x[0] for x in enumerate(labels)}\n",
    "reverse_lookup = {labels[k]:k for k in labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########################################\n",
      "           MAKING TRAINING DATA           \n",
      "##########################################\n",
      "##########################################\n",
      "                TRAIN DATA                \n",
      "##########################################\n",
      "          Day   Month        Label  SequenceNumber  Path9  Path10  Path11  \\\n",
      "count  2034.0  2034.0  2034.000000     2034.000000    0.0     0.0     0.0   \n",
      "mean     14.0    11.0     0.500000      508.000000    NaN     NaN     NaN   \n",
      "std       0.0     0.0     0.500123      293.654665    NaN     NaN     NaN   \n",
      "min      14.0    11.0     0.000000        0.000000    NaN     NaN     NaN   \n",
      "25%      14.0    11.0     0.000000      254.000000    NaN     NaN     NaN   \n",
      "50%      14.0    11.0     0.500000      508.000000    NaN     NaN     NaN   \n",
      "75%      14.0    11.0     1.000000      762.000000    NaN     NaN     NaN   \n",
      "max      14.0    11.0     1.000000     1016.000000    NaN     NaN     NaN   \n",
      "\n",
      "       Path12  Path13  Path14  Path15  Path16  Path17  Path18  Path19  Path20  \\\n",
      "count     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "mean      NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
      "std       NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
      "min       NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
      "25%       NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
      "50%       NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
      "75%       NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
      "max       NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
      "\n",
      "       Path21  Path22  \n",
      "count     0.0     0.0  \n",
      "mean      NaN     NaN  \n",
      "std       NaN     NaN  \n",
      "min       NaN     NaN  \n",
      "25%       NaN     NaN  \n",
      "50%       NaN     NaN  \n",
      "75%       NaN     NaN  \n",
      "max       NaN     NaN  \n",
      "   Category  Day  Month  Label  SequenceNumber       Set  \\\n",
      "0  no_voice   14     11      1             261  Training   \n",
      "1  no_voice   14     11      0             872  Training   \n",
      "2  no_voice   14     11      0              74  Training   \n",
      "3  no_voice   14     11      1             185  Training   \n",
      "4  no_voice   14     11      1             639   Testing   \n",
      "5  no_voice   14     11      0             724  Training   \n",
      "6  no_voice   14     11      0             370  Training   \n",
      "7  no_voice   14     11      1             504  Training   \n",
      "8  no_voice   14     11      0               7  Training   \n",
      "9  no_voice   14     11      1             490  Training   \n",
      "\n",
      "                                               Path1  \\\n",
      "0  /Users/kyy/demo/images_scaled/taylor_11_14/no_...   \n",
      "1  /Users/kyy/demo/images_scaled/taylor_11_14/no_...   \n",
      "2  /Users/kyy/demo/images_scaled/taylor_11_14/no_...   \n",
      "3  /Users/kyy/demo/images_scaled/taylor_11_14/no_...   \n",
      "4  /Users/kyy/demo/images_scaled/taylor_11_14/no_...   \n",
      "5  /Users/kyy/demo/images_scaled/taylor_11_14/no_...   \n",
      "6  /Users/kyy/demo/images_scaled/taylor_11_14/no_...   \n",
      "7  /Users/kyy/demo/images_scaled/taylor_11_14/no_...   \n",
      "8  /Users/kyy/demo/images_scaled/taylor_11_14/no_...   \n",
      "9  /Users/kyy/demo/images_scaled/taylor_11_14/no_...   \n",
      "\n",
      "                                               Path2  \\\n",
      "0  /Users/kyy/demo/images_scaled/taylor_11_14/no_...   \n",
      "1  /Users/kyy/demo/images_scaled/taylor_11_14/no_...   \n",
      "2  /Users/kyy/demo/images_scaled/taylor_11_14/no_...   \n",
      "3  /Users/kyy/demo/images_scaled/taylor_11_14/no_...   \n",
      "4  /Users/kyy/demo/images_scaled/taylor_11_14/no_...   \n",
      "5  /Users/kyy/demo/images_scaled/taylor_11_14/no_...   \n",
      "6  /Users/kyy/demo/images_scaled/taylor_11_14/no_...   \n",
      "7  /Users/kyy/demo/images_scaled/taylor_11_14/no_...   \n",
      "8  /Users/kyy/demo/images_scaled/taylor_11_14/no_...   \n",
      "9  /Users/kyy/demo/images_scaled/taylor_11_14/no_...   \n",
      "\n",
      "                                               Path3  \\\n",
      "0  /Users/kyy/demo/images_scaled/taylor_11_14/no_...   \n",
      "1  /Users/kyy/demo/images_scaled/taylor_11_14/no_...   \n",
      "2  /Users/kyy/demo/images_scaled/taylor_11_14/no_...   \n",
      "3  /Users/kyy/demo/images_scaled/taylor_11_14/no_...   \n",
      "4  /Users/kyy/demo/images_scaled/taylor_11_14/no_...   \n",
      "5  /Users/kyy/demo/images_scaled/taylor_11_14/no_...   \n",
      "6  /Users/kyy/demo/images_scaled/taylor_11_14/no_...   \n",
      "7  /Users/kyy/demo/images_scaled/taylor_11_14/no_...   \n",
      "8  /Users/kyy/demo/images_scaled/taylor_11_14/no_...   \n",
      "9  /Users/kyy/demo/images_scaled/taylor_11_14/no_...   \n",
      "\n",
      "                                               Path4   ...    Path13  Path14  \\\n",
      "0  /Users/kyy/demo/images_scaled/taylor_11_14/no_...   ...       NaN     NaN   \n",
      "1  /Users/kyy/demo/images_scaled/taylor_11_14/no_...   ...       NaN     NaN   \n",
      "2  /Users/kyy/demo/images_scaled/taylor_11_14/no_...   ...       NaN     NaN   \n",
      "3  /Users/kyy/demo/images_scaled/taylor_11_14/no_...   ...       NaN     NaN   \n",
      "4  /Users/kyy/demo/images_scaled/taylor_11_14/no_...   ...       NaN     NaN   \n",
      "5  /Users/kyy/demo/images_scaled/taylor_11_14/no_...   ...       NaN     NaN   \n",
      "6  /Users/kyy/demo/images_scaled/taylor_11_14/no_...   ...       NaN     NaN   \n",
      "7  /Users/kyy/demo/images_scaled/taylor_11_14/no_...   ...       NaN     NaN   \n",
      "8  /Users/kyy/demo/images_scaled/taylor_11_14/no_...   ...       NaN     NaN   \n",
      "9  /Users/kyy/demo/images_scaled/taylor_11_14/no_...   ...       NaN     NaN   \n",
      "\n",
      "   Path15  Path16  Path17  Path18  Path19  Path20  Path21  Path22  \n",
      "0     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN  \n",
      "1     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN  \n",
      "2     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN  \n",
      "3     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN  \n",
      "4     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN  \n",
      "5     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN  \n",
      "6     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN  \n",
      "7     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN  \n",
      "8     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN  \n",
      "9     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN  \n",
      "\n",
      "[10 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "# Make the training data\n",
    "print_and_log_header(\"MAKING TRAINING DATA\")\n",
    "train_data = pd.read_csv(train_csv)\n",
    "\n",
    "# Filter the training data\n",
    "train_data = select_categories(train_data, CATEGORY)\n",
    "train_data = select_channels(train_data, CHANNELS)\n",
    "train_data = select_labels(train_data, LABELS)\n",
    "train_data = select_months(train_data, MONTHS)\n",
    "train_data = select_days(train_data, DAYS)\n",
    "# train_data = remove_voice(train_data)\n",
    "\n",
    "train_data = train_data.sample(frac=1).reset_index(drop=True)\n",
    "tdcopy = pd.DataFrame(train_data)\n",
    "train_data[\"Label\"] = train_data[\"Label\"].map(labels)\n",
    "\n",
    "if VERBOSE:\n",
    "    print_and_log_header(\"TRAIN DATA\")\n",
    "    print_and_log(train_data.describe())\n",
    "    print_and_log(train_data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Separate Labels\n",
    "train_labels = train_data.pop(target_label)\n",
    "img_paths = [\"Path{}\".format(channel) for channel in CHANNELS]\n",
    "train_data = train_data[img_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########################################\n",
      "          Parsing Training Data           \n",
      "##########################################\n",
      "Start: 2018-11-14 08:47:24.013200\n",
      "End: 2018-11-14 08:47:24.324182\n",
      "Finished in 00:00:00:00.31\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Vectors of filenames.\n",
    "t_f, v_f, s_f = [], [], []\n",
    "for i in range(1, 1 + len(CHANNELS)):\n",
    "    channel = CHANNELS[i-1]\n",
    "    l = \"Path{}\".format(channel)\n",
    "    t_f.append(tf.constant(train_data[l]))\n",
    "\n",
    "# `labels[i]` is the label for the image in `filenames[i]\n",
    "# Vectors of labels\n",
    "train_labels = tf.constant(train_labels)\n",
    "\n",
    "# Make datasets from filenames and labels\n",
    "train_data = tf.data.Dataset.from_tensor_slices((train_labels, *t_f))\n",
    "print_and_log_header(\"Parsing Training Data\")\n",
    "train_data = timer(lambda: train_data.map(_parse_function))\n",
    "print_and_log(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########################################\n",
      "                 TRAINING                 \n",
      "##########################################\n",
      "<MapDataset shapes: ((1, 28, 28, 4), ()), types: (tf.float32, tf.int64)>\n",
      "<class 'tensorflow.python.data.ops.dataset_ops.MapDataset'>\n"
     ]
    }
   ],
   "source": [
    "print_and_log_header(\"TRAINING\")\n",
    "print_and_log(train_data)\n",
    "print_and_log(type(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the Estimator\n",
    "classifier = tf.estimator.Estimator(model_fn=model_fn, model_dir=paths[\"Model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the input functions.\n",
    "training_eval_input_fn = create_predict_input_fn(train_data, DEFAULT_BS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########################################\n",
      "                 OUTLIERS                 \n",
      "##########################################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Probability</th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>SequenceNumber</th>\n",
       "      <th>Path9</th>\n",
       "      <th>Path10</th>\n",
       "      <th>Path11</th>\n",
       "      <th>Path12</th>\n",
       "      <th>Path13</th>\n",
       "      <th>Path14</th>\n",
       "      <th>Path15</th>\n",
       "      <th>Path16</th>\n",
       "      <th>Path17</th>\n",
       "      <th>Path18</th>\n",
       "      <th>Path19</th>\n",
       "      <th>Path20</th>\n",
       "      <th>Path21</th>\n",
       "      <th>Path22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>203.000000</td>\n",
       "      <td>203.000000</td>\n",
       "      <td>203.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>203.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.536490</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>371.423645</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.498547</td>\n",
       "      <td>0.022051</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>293.038128</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500462</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.517152</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>127.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.535731</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>301.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.556068</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>604.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.575828</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1013.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Prediction  Probability    Day  Month  SequenceNumber  Path9  Path10  \\\n",
       "count  203.000000   203.000000  203.0  203.0      203.000000    0.0     0.0   \n",
       "mean     0.551724     0.536490   14.0   11.0      371.423645    NaN     NaN   \n",
       "std      0.498547     0.022051    0.0    0.0      293.038128    NaN     NaN   \n",
       "min      0.000000     0.500462   14.0   11.0        0.000000    NaN     NaN   \n",
       "25%      0.000000     0.517152   14.0   11.0      127.500000    NaN     NaN   \n",
       "50%      1.000000     0.535731   14.0   11.0      301.000000    NaN     NaN   \n",
       "75%      1.000000     0.556068   14.0   11.0      604.500000    NaN     NaN   \n",
       "max      1.000000     0.575828   14.0   11.0     1013.000000    NaN     NaN   \n",
       "\n",
       "       Path11  Path12  Path13  Path14  Path15  Path16  Path17  Path18  Path19  \\\n",
       "count     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "mean      NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "std       NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "min       NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "25%       NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "50%       NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "75%       NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "max       NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "\n",
       "       Path20  Path21  Path22  \n",
       "count     0.0     0.0     0.0  \n",
       "mean      NaN     NaN     NaN  \n",
       "std       NaN     NaN     NaN  \n",
       "min       NaN     NaN     NaN  \n",
       "25%       NaN     NaN     NaN  \n",
       "50%       NaN     NaN     NaN  \n",
       "75%       NaN     NaN     NaN  \n",
       "max       NaN     NaN     NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########################################\n",
      "                 KEEPERS                  \n",
      "##########################################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Probability</th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>SequenceNumber</th>\n",
       "      <th>Path9</th>\n",
       "      <th>Path10</th>\n",
       "      <th>Path11</th>\n",
       "      <th>Path12</th>\n",
       "      <th>Path13</th>\n",
       "      <th>Path14</th>\n",
       "      <th>Path15</th>\n",
       "      <th>Path16</th>\n",
       "      <th>Path17</th>\n",
       "      <th>Path18</th>\n",
       "      <th>Path19</th>\n",
       "      <th>Path20</th>\n",
       "      <th>Path21</th>\n",
       "      <th>Path22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1831.000000</td>\n",
       "      <td>1831.000000</td>\n",
       "      <td>1831.0</td>\n",
       "      <td>1831.0</td>\n",
       "      <td>1831.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.548880</td>\n",
       "      <td>0.832114</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>523.141999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.497741</td>\n",
       "      <td>0.121567</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>289.864688</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.577752</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.733487</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>277.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.854300</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>531.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.934126</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>770.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999698</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1016.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Prediction  Probability     Day   Month  SequenceNumber  Path9  \\\n",
       "count  1831.000000  1831.000000  1831.0  1831.0     1831.000000    0.0   \n",
       "mean      0.548880     0.832114    14.0    11.0      523.141999    NaN   \n",
       "std       0.497741     0.121567     0.0     0.0      289.864688    NaN   \n",
       "min       0.000000     0.577752    14.0    11.0        0.000000    NaN   \n",
       "25%       0.000000     0.733487    14.0    11.0      277.500000    NaN   \n",
       "50%       1.000000     0.854300    14.0    11.0      531.000000    NaN   \n",
       "75%       1.000000     0.934126    14.0    11.0      770.000000    NaN   \n",
       "max       1.000000     0.999698    14.0    11.0     1016.000000    NaN   \n",
       "\n",
       "       Path10  Path11  Path12  Path13  Path14  Path15  Path16  Path17  Path18  \\\n",
       "count     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "mean      NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "std       NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "min       NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "25%       NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "50%       NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "75%       NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "max       NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "\n",
       "       Path19  Path20  Path21  Path22  \n",
       "count     0.0     0.0     0.0     0.0  \n",
       "mean      NaN     NaN     NaN     NaN  \n",
       "std       NaN     NaN     NaN     NaN  \n",
       "min       NaN     NaN     NaN     NaN  \n",
       "25%       NaN     NaN     NaN     NaN  \n",
       "50%       NaN     NaN     NaN     NaN  \n",
       "75%       NaN     NaN     NaN     NaN  \n",
       "max       NaN     NaN     NaN     NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create predicitons and remove 10% lowest confidence rows\n",
    "results = [x for x in classifier.predict(input_fn=training_eval_input_fn)]\n",
    "classes = [x[\"classes\"] for x in results]\n",
    "probs = [x[\"probabilities\"] for x in results]\n",
    "probs = pd.Series(probs)\n",
    "probs = probs.apply(lambda x: max(x))\n",
    "tdf = pd.DataFrame({\"Prediction\":classes, \"Probability\":probs})\n",
    "num_items = tdf.shape[0]\n",
    "for k in tdcopy:\n",
    "    tdf[k] = tdcopy[k]\n",
    "outliers = tdf.nsmallest(int(num_items * OUTLIER_PERCENTAGE), \"Probability\")\n",
    "keepers = tdf.append(outliers, ignore_index=True).drop_duplicates([\"Day\", \"Month\", \"Label\", \"SequenceNumber\"], keep=False).reset_index(drop=True)\n",
    "outliers = outliers.reset_index(drop=True)\n",
    "keepers[\"Label\"] = keepers[\"Label\"].apply(lambda x: reverse_lookup[x])\n",
    "outliers[\"Label\"] = outliers[\"Label\"].apply(lambda x: reverse_lookup[x])\n",
    "if DISPLAY:\n",
    "    print_and_log_header(\"OUTLIERS\")\n",
    "    display.display(outliers.describe())\n",
    "    print_and_log_header(\"KEEPERS\")\n",
    "    display.display(keepers.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "keepers.drop([\"Prediction\", \"Probability\"], axis=1, inplace=True)\n",
    "outliers.drop([\"Prediction\", \"Probability\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTLIERS\n",
      "\tTraining:\t162\n",
      "\tValidation:\t16\n",
      "\tTesting:\t25\n"
     ]
    }
   ],
   "source": [
    "s = outliers[\"Set\"]\n",
    "tra = sum(s.apply(lambda x: 1 if x == \"Training\" else 0))\n",
    "val = sum(s.apply(lambda x: 1 if x == \"Validation\" else 0))\n",
    "tst = sum(s.apply(lambda x: 1 if x == \"Testing\" else 0))\n",
    "print(\"OUTLIERS\\n\\tTraining:\\t{}\\n\\tValidation:\\t{}\\n\\tTesting:\\t{}\".format(tra, val, tst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved KEEPERS to 'keepers_11_14_1234.csv'\n",
      "Saved OUTLIERS to 'outliers_11_14_1234.csv'\n"
     ]
    }
   ],
   "source": [
    "KEEPERS_NAME = \"keepers_{:02}_{:02}_{}.csv\".format(MONTHS[0], DAYS[0], NUMS)\n",
    "OUTLIERS_NAME = \"outliers_{:02}_{:02}_{}.csv\".format(MONTHS[0], DAYS[0], NUMS)\n",
    "keepers.to_csv(KEEPERS_NAME)\n",
    "print(\"Saved KEEPERS to '{}'\".format(KEEPERS_NAME))\n",
    "outliers.to_csv(OUTLIERS_NAME)\n",
    "print(\"Saved OUTLIERS to '{}'\".format(OUTLIERS_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
