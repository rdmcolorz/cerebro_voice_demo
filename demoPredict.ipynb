{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import IPython.display as ipd\n",
    "import random\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as py\n",
    "from IPython import display\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import subprocess\n",
    "%matplotlib inline\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "# NOTES\n",
    "NOTES = \"28x28\"\n",
    "\n",
    "# VARS\n",
    "target_label = \"Label\"\n",
    "id_label = \"fname\"\n",
    "OUTSTR = \"A{:.4f}_Type{}_UDR{}_THRESH{:5.3f}_DROP{}_LR{}_S{}_B{}{}.csv\"\n",
    "IMG_EXT = \".png\"\n",
    "VERBOSE = True\n",
    "DISPLAY = True\n",
    "TEST = False\n",
    "MFCC = False\n",
    "TPU = False\n",
    "RESIZE = True\n",
    "INPUT_WIDTH = 128\n",
    "INPUT_HEIGHT = 128\n",
    "TARGET_WIDTH = 28 if RESIZE else INPUT_WIDTH\n",
    "TARGET_HEIGHT = 28 if RESIZE else INPUT_HEIGHT\n",
    "DECAY_RATE = 0.9\n",
    "IMG_CHANNELS = 3\n",
    "DROPOUT = 0.4\n",
    "TYPE = \"CNN\"\n",
    "DEFAULT_BS = 128 # default batch size\n",
    "UNK_DROP_RATE = 1.0 # drop 100% of unknown categories\n",
    "\n",
    "CATEGORY = [\"no_voice\"]\n",
    "LABELS = [\"yes\", \"no\", \"test\"]\n",
    "CHANNELS = [1,2,3,5,6,7,8]\n",
    "NUMS = ''.join([str(x) for x in CHANNELS])\n",
    "MONTHS = [8]\n",
    "DAYS = [11]\n",
    "\n",
    "if TEST:\n",
    "    LEARNING_STEPS = 100\n",
    "    SPP = 4\n",
    "    LEARNING_RATE = .05\n",
    "    BATCH_SIZE = 32\n",
    "    VERBOSITY = 1000\n",
    "    TEST_SIZE = 1000\n",
    "    SHUFFLE_SIZE = 64\n",
    "else:\n",
    "    LEARNING_STEPS = 5000\n",
    "    SPP = 200\n",
    "    LEARNING_RATE = .025\n",
    "    BATCH_SIZE = 64\n",
    "    VERBOSITY = 1000\n",
    "    SHUFFLE_SIZE = 256\n",
    "\n",
    "def curr_time():\n",
    "    return datetime.now() - timedelta(hours=7) # offset from UTC to PST\n",
    "\n",
    "ROOT = os.getcwd() + \"/\"\n",
    "if CATEGORY[0] == \"no_voice\":\n",
    "    RUN_ROOT = ROOT+\"NONVOCAL_RUNS_YN_{:02}_{:02}/\".format(MONTHS[0], DAYS[0])\n",
    "else:\n",
    "    RUN_ROOT = ROOT+\"VOCAL_RUNS_YN_{:02}_{:02}/\".format(MONTHS[0], DAYS[0])\n",
    "RUN_ROOT_LOG = RUN_ROOT+\"logs/\"\n",
    "\n",
    "# PATHS\n",
    "paths = {\n",
    "    \"Training\":ROOT+\"paths_scaled_combined.csv\",\n",
    "    \"Model\":RUN_ROOT+\"demoModelOutliers\",\n",
    "    \"Logs\":RUN_ROOT_LOG+\"{}_{}/\".format(NUMS, datetime.strftime(curr_time(), \"%b%d%Y_%H%M%S\"))\n",
    "}\n",
    "paths[\"Log\"] = paths[\"Logs\"] + \"log.txt\"\n",
    "if not os.path.isdir(RUN_ROOT):\n",
    "    os.mkdir(RUN_ROOT)\n",
    "if not os.path.isdir(RUN_ROOT_LOG):\n",
    "    os.mkdir(RUN_ROOT_LOG)\n",
    "if not os.path.isdir(paths[\"Logs\"]):\n",
    "    os.mkdir(paths[\"Logs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_header(s):\n",
    "    return (\"#\" * 42) + (\"\\n{:^42}\\n\".format(s)) + (\"#\" * 42)\n",
    "    \n",
    "def print_and_log(s):\n",
    "    with open(paths[\"Log\"], 'a') as log:\n",
    "        log.write(str(s))\n",
    "        log.write(\"\\n\")\n",
    "    print(s)\n",
    "        \n",
    "def print_and_log_header(s):\n",
    "    h = make_header(str(s))\n",
    "    with open(paths[\"Log\"], 'a') as log:\n",
    "        log.write(h)\n",
    "        log.write(\"\\n\")\n",
    "    print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sec_to_str(secs):\n",
    "    ms = secs - int(secs)\n",
    "    days = int(secs // (24 * 3600))\n",
    "    hours = int((secs % ((24 * 3600))) // 3600)\n",
    "    minutes = int((secs % 3600) // 60)\n",
    "    seconds = int(secs % 60)\n",
    "    return \"{:02}:{:02}:{:02}:{:02}.{}\".format(days, hours, minutes, seconds, \"{:.3}\".format(ms)[2:])\n",
    "\n",
    "def timer(f, *args):\n",
    "    print_and_log(\"Start: {}\".format(curr_time()))\n",
    "    start = time.time()\n",
    "    result = f(*args)\n",
    "    end = time.time()\n",
    "    print_and_log(\"End: {}\".format(curr_time()))\n",
    "    print_and_log(\"Finished in {}\".format(sec_to_str(end - start)))\n",
    "    return result\n",
    "\n",
    "def preprocess(samples, sample_rate):\n",
    "    padded = np.zeros(sample_rate)\n",
    "    samples = samples[:sample_rate]\n",
    "    padded[:samples.shape[0]] = samples\n",
    "    return padded\n",
    "\n",
    "def select_labels(df, allowed):\n",
    "    return df[df['Label'].isin(allowed)]\n",
    "    \n",
    "def select_categories(df, allowed):\n",
    "    return df[df['Category'].isin(allowed)]\n",
    "\n",
    "def select_channels(df, allowed):\n",
    "    labels = []\n",
    "    for i in range(1, 9):\n",
    "        if i not in allowed:\n",
    "            labels.append(\"Path{}\".format(i))\n",
    "    return df.drop(labels, axis=1)\n",
    "\n",
    "def select_days(df, allowed):\n",
    "    return df[df['Day'].isin(allowed)]\n",
    "\n",
    "def select_months(df, allowed):\n",
    "    return df[df['Month'].isin(allowed)]\n",
    "\n",
    "def select_sets(df, allowed):\n",
    "    return df[df['Set'].isin(allowed)]\n",
    "\n",
    "def remove_voice(df):\n",
    "    return df.drop([\"Path4\"], axis=1)\n",
    "\n",
    "def str_to_l(x):\n",
    "    return [int(n) for n in x if n <= '9' and n >= '0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "def _parse_function(label, *filenames):\n",
    "    global count\n",
    "    count += 1\n",
    "    if count % VERBOSITY == 0:\n",
    "        print_and_log(\"\\tProcessed {}th image\".format(count))\n",
    "    expected_shape = tf.constant([1, INPUT_HEIGHT, INPUT_WIDTH, IMG_CHANNELS])\n",
    "    image = None\n",
    "    for filename in filenames:\n",
    "        image_string = tf.read_file(filename)\n",
    "        image_decoded = tf.image.decode_image(image_string, channels=IMG_CHANNELS)\n",
    "        image_decoded = tf.image.convert_image_dtype(image_decoded, tf.float32)\n",
    "        image_decoded = tf.reshape(image_decoded, expected_shape)\n",
    "        image_decoded = tf.image.rgb_to_grayscale(image_decoded)\n",
    "        if RESIZE:\n",
    "            image_decoded = tf.image.resize_bicubic(image_decoded, [TARGET_HEIGHT, TARGET_WIDTH])\n",
    "        if image is not None:\n",
    "            image = tf.concat([image, image_decoded], 3)\n",
    "        else:\n",
    "            image = image_decoded\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "def _parse_demo_function(*filenames):\n",
    "    global count\n",
    "    count += 1\n",
    "    if count % VERBOSITY == 0:\n",
    "        print_and_log(\"\\tProcessed {}th image\".format(count))\n",
    "    expected_shape = tf.constant([1, INPUT_HEIGHT, INPUT_WIDTH, IMG_CHANNELS])\n",
    "    image = None\n",
    "    for filename in filenames:\n",
    "        image_string = tf.read_file(filename)\n",
    "        image_decoded = tf.image.decode_image(image_string, channels=IMG_CHANNELS)\n",
    "        image_decoded = tf.image.convert_image_dtype(image_decoded, tf.float32)\n",
    "        image_decoded = tf.reshape(image_decoded, expected_shape)\n",
    "        image_decoded = tf.image.rgb_to_grayscale(image_decoded)\n",
    "        if RESIZE:\n",
    "            image_decoded = tf.image.resize_bicubic(image_decoded, [TARGET_HEIGHT, TARGET_WIDTH])\n",
    "        if image is not None:\n",
    "            image = tf.concat([image, image_decoded], 3)\n",
    "        else:\n",
    "            image = image_decoded\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode):\n",
    "    input_layer = tf.reshape(features, [-1, TARGET_HEIGHT, TARGET_WIDTH, len(CHANNELS)])\n",
    "    pool = input_layer\n",
    "\n",
    "    for num_filters in [32, 64]:\n",
    "        conv = tf.layers.conv2d(\n",
    "            inputs=pool,\n",
    "            filters=num_filters,\n",
    "            kernel_size=[5, 5],\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu)\n",
    "        pool = tf.layers.max_pooling2d(inputs=conv, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    # Dense Layer\n",
    "    pool = tf.layers.flatten(pool)\n",
    "    dense = tf.layers.dense(inputs=pool, units=1024, activation=tf.nn.relu)\n",
    "    dropout = tf.layers.dropout(inputs=dense, rate=DROPOUT, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "    # Logits Layer\n",
    "    logits = tf.layers.dense(inputs=dropout, units=num_labels)\n",
    "    \n",
    "    predictions = {\n",
    "        \"classes\": tf.argmax(input=logits, axis=1),\n",
    "        \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "    }\n",
    "    if not TPU:\n",
    "        tf.summary.histogram(\"predictions\", predictions[\"probabilities\"])\n",
    "        tf.summary.histogram(\"classes\", predictions[\"classes\"])\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "    learning_rate = tf.train.exponential_decay(LEARNING_RATE, tf.train.get_global_step(), SPP, DECAY_RATE, staircase=True)\n",
    "    \n",
    "    # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "    predictions[\"loss\"] = loss\n",
    "    \n",
    "    # Configure the Training Op (for TRAIN mode)\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "        if TPU:\n",
    "            optimizer = tf.contrib.tpu.CrossShardOptimizer(optimizer)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "    # Add evaluation metrics (for EVAL mode)\n",
    "    eval_metric_ops = {\n",
    "        \"accuracy\": tf.metrics.accuracy(\n",
    "            labels=labels, predictions=predictions[\"classes\"])}\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_input_fn(dataset, batch_size, num_epochs=None):\n",
    "    def _input_fn(num_epochs=None, shuffle=True):\n",
    "        ds = dataset.batch(batch_size).repeat(num_epochs)\n",
    "        if shuffle:\n",
    "            ds = ds.shuffle(SHUFFLE_SIZE)\n",
    "        feature_batch, label_batch = ds.make_one_shot_iterator().get_next()\n",
    "        return feature_batch, label_batch\n",
    "    return _input_fn\n",
    "\n",
    "def create_predict_input_fn(dataset, batch_size):\n",
    "    def _input_fn():\n",
    "        ds = dataset.batch(batch_size)\n",
    "        feature_batch, label_batch = ds.make_one_shot_iterator().get_next()\n",
    "        return feature_batch, label_batch\n",
    "    return _input_fn\n",
    "\n",
    "def train_helper(steps_per_period):\n",
    "    classifier.train(\n",
    "        input_fn=train_input_fn,\n",
    "        steps=steps_per_period)\n",
    "    training_stats = classifier.evaluate(input_fn=training_eval_input_fn)\n",
    "    validation_stats = classifier.evaluate(input_fn=validation_eval_input_fn)\n",
    "    t_ll = training_stats[\"loss\"]\n",
    "    t_acc = 100 * training_stats[\"accuracy\"]\n",
    "    v_ll = validation_stats[\"loss\"]\n",
    "    v_acc = 100 * validation_stats[\"accuracy\"]\n",
    "    return classifier, t_ll, v_ll, t_acc, v_acc\n",
    "\n",
    "def train():\n",
    "    periods = LEARNING_STEPS // SPP\n",
    "    steps_per_period = LEARNING_STEPS // periods\n",
    "    t_accs, v_accs = [], []\n",
    "    t_lls, v_lls = [], []\n",
    "    print_and_log(\"Training model...\\nMetrics:\")\n",
    "    print_and_log(\"\\tPERIOD\\tRATE\\tTYPE\\tTRAIN.\\tVALID.\\tTIME\")\n",
    "    for period in range(periods):\n",
    "        lr = LEARNING_RATE * (DECAY_RATE ** ((period * SPP) / SPP))\n",
    "        classifier, t_ll, v_ll, t_acc, v_acc = train_helper(steps_per_period)\n",
    "        print_and_log(\"\\t{}\\t{:.5f}\\tLgLs\\t{:.2f}\\t{:.2f}\\t{}\".format(period, lr, t_ll, v_ll, curr_time()))\n",
    "        print_and_log(\"\\t\\t\\tAcc.\\t{:.2f}%\\t{:.2f}%\\n\".format(t_acc, v_acc))\n",
    "        t_lls.append(t_ll)\n",
    "        v_lls.append(v_ll)\n",
    "        t_accs.append(t_acc)\n",
    "        v_accs.append(v_acc)\n",
    "    v_accuracy = v_accs[-1]\n",
    "    return classifier, v_accuracy, t_lls, v_lls, t_accs, v_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(paths[\"Log\"], 'w') as log:\n",
    "    log.write(make_header(\"Starting Script\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create variables for the paths\n",
    "# train_csv = paths[\"Training\"]\n",
    "\n",
    "# Store the labels to train\n",
    "all_labels = LABELS\n",
    "labels = [\"yes\", \"no\", \"stop\", \"unknown\"]\n",
    "num_labels = len(labels) - 1\n",
    "labels = {x[1]:x[0] for x in enumerate(labels)}\n",
    "reverse_lookup = {labels[k]:k for k in labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########################################\n",
      "             MAKING DEMO DATA             \n",
      "##########################################\n",
      "##########################################\n",
      "                DEMO DATA                 \n",
      "##########################################\n",
      "        Day  Month  SequenceNumber  Path5  Path9  Path10  Path11  Path12  \\\n",
      "count   1.0    1.0             1.0    0.0    0.0     0.0     0.0     0.0   \n",
      "mean   20.0    9.0             0.0    NaN    NaN     NaN     NaN     NaN   \n",
      "std     NaN    NaN             NaN    NaN    NaN     NaN     NaN     NaN   \n",
      "min    20.0    9.0             0.0    NaN    NaN     NaN     NaN     NaN   \n",
      "25%    20.0    9.0             0.0    NaN    NaN     NaN     NaN     NaN   \n",
      "50%    20.0    9.0             0.0    NaN    NaN     NaN     NaN     NaN   \n",
      "75%    20.0    9.0             0.0    NaN    NaN     NaN     NaN     NaN   \n",
      "max    20.0    9.0             0.0    NaN    NaN     NaN     NaN     NaN   \n",
      "\n",
      "       Path13  Path14  Path15  Path16  Path17  Path18  Path19  Path20  Path21  \\\n",
      "count     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "mean      NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
      "std       NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
      "min       NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
      "25%       NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
      "50%       NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
      "75%       NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
      "max       NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
      "\n",
      "       Path22  \n",
      "count     0.0  \n",
      "mean      NaN  \n",
      "std       NaN  \n",
      "min       NaN  \n",
      "25%       NaN  \n",
      "50%       NaN  \n",
      "75%       NaN  \n",
      "max       NaN  \n",
      "   Category  Day  Month Label  SequenceNumber       Set  \\\n",
      "0  no_voice   20      9  test               0  Training   \n",
      "\n",
      "                                               Path1  \\\n",
      "0  /Users/42robotics/Desktop/demoday/Subvoc/image...   \n",
      "\n",
      "                                               Path2  \\\n",
      "0  /Users/42robotics/Desktop/demoday/Subvoc/image...   \n",
      "\n",
      "                                               Path3  \\\n",
      "0  /Users/42robotics/Desktop/demoday/Subvoc/image...   \n",
      "\n",
      "                                               Path4   ...    Path13 Path14  \\\n",
      "0  /Users/42robotics/Desktop/demoday/Subvoc/image...   ...       NaN    NaN   \n",
      "\n",
      "  Path15 Path16  Path17  Path18  Path19  Path20  Path21  Path22  \n",
      "0    NaN    NaN     NaN     NaN     NaN     NaN     NaN     NaN  \n",
      "\n",
      "[1 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "# Make the training data\n",
    "print_and_log_header(\"MAKING DEMO DATA\")\n",
    "demo_data = pd.read_csv(\"./demo.csv\")\n",
    "\n",
    "# # Filter the demo data\n",
    "# demo_data = select_channels(demo_data, all_labels)\n",
    "\n",
    "\n",
    "# train_data = train_data.sample(frac=1).reset_index(drop=True)\n",
    "# train_data[\"Label\"] = train_data[\"Label\"].map(labels)\n",
    "\n",
    "if VERBOSE:\n",
    "    print_and_log_header(\"DEMO DATA\")\n",
    "    print_and_log(demo_data.describe())\n",
    "    print_and_log(demo_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>Label</th>\n",
       "      <th>SequenceNumber</th>\n",
       "      <th>Set</th>\n",
       "      <th>Path1</th>\n",
       "      <th>Path2</th>\n",
       "      <th>Path3</th>\n",
       "      <th>Path4</th>\n",
       "      <th>...</th>\n",
       "      <th>Path13</th>\n",
       "      <th>Path14</th>\n",
       "      <th>Path15</th>\n",
       "      <th>Path16</th>\n",
       "      <th>Path17</th>\n",
       "      <th>Path18</th>\n",
       "      <th>Path19</th>\n",
       "      <th>Path20</th>\n",
       "      <th>Path21</th>\n",
       "      <th>Path22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no_voice</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>Training</td>\n",
       "      <td>/Users/42robotics/Desktop/demoday/Subvoc/image...</td>\n",
       "      <td>/Users/42robotics/Desktop/demoday/Subvoc/image...</td>\n",
       "      <td>/Users/42robotics/Desktop/demoday/Subvoc/image...</td>\n",
       "      <td>/Users/42robotics/Desktop/demoday/Subvoc/image...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Category  Day  Month Label  SequenceNumber       Set  \\\n",
       "0  no_voice   20      9  test               0  Training   \n",
       "\n",
       "                                               Path1  \\\n",
       "0  /Users/42robotics/Desktop/demoday/Subvoc/image...   \n",
       "\n",
       "                                               Path2  \\\n",
       "0  /Users/42robotics/Desktop/demoday/Subvoc/image...   \n",
       "\n",
       "                                               Path3  \\\n",
       "0  /Users/42robotics/Desktop/demoday/Subvoc/image...   \n",
       "\n",
       "                                               Path4   ...    Path13 Path14  \\\n",
       "0  /Users/42robotics/Desktop/demoday/Subvoc/image...   ...       NaN    NaN   \n",
       "\n",
       "  Path15 Path16  Path17  Path18  Path19  Path20  Path21  Path22  \n",
       "0    NaN    NaN     NaN     NaN     NaN     NaN     NaN     NaN  \n",
       "\n",
       "[1 rows x 28 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Grab subset of the data for testing purposes\n",
    "# if TEST:\n",
    "#     train_data = train_data[:TEST_SIZE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 80/10/10 training/validation/test split\n",
    "# validation_data = select_sets(train_data, [\"Validation\"])\n",
    "# test_data = select_sets(train_data, [\"Testing\"])\n",
    "# train_data = select_sets(train_data, [\"Training\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ids = demo_data[\"Path{}\".format(CHANNELS[0])] # store the png filenames for output\n",
    "# if VERBOSE:\n",
    "#     print_and_log_header(\"IDS\")\n",
    "#     print_and_log(ids.describe())\n",
    "#     print_and_log(ids.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Separate Labels\n",
    "# train_labels = train_data.pop(target_label)\n",
    "# validation_labels = validation_data.pop(target_label)\n",
    "# test_labels = test_data.pop(target_label)\n",
    "# img_paths = [\"Path{}\".format(channel) for channel in CHANNELS]\n",
    "# train_data = train_data[img_paths]\n",
    "# validation_data = validation_data[img_paths]\n",
    "# test_data = test_data[img_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Category  Day  Month Label  SequenceNumber       Set  Path9  Path10  \\\n",
      "0  no_voice   20      9  test               0  Training    NaN     NaN   \n",
      "1  no_voice   20      9  test               0  Training    NaN     NaN   \n",
      "\n",
      "   Path11  Path12  Path13  Path14  Path15  Path16  Path17  Path18  Path19  \\\n",
      "0     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
      "1     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
      "\n",
      "   Path20  Path21  Path22  \n",
      "0     NaN     NaN     NaN  \n",
      "1     NaN     NaN     NaN  \n",
      "##########################################\n",
      "          Parsing Training Data           \n",
      "##########################################\n",
      "Start: 2018-09-18 17:09:08.558061\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'map'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-8473b76a7ac6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# print_and_log_header(\"Parsing Testing Data\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# test_data = timer(lambda: test_data.map(_parse_function))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mdemo_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdemo_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_parse_demo_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0mprint_and_log\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nDone!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-9b4cbedd9f3c>\u001b[0m in \u001b[0;36mtimer\u001b[0;34m(f, *args)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint_and_log\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Start: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mprint_and_log\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"End: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-8473b76a7ac6>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# print_and_log_header(\"Parsing Testing Data\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# test_data = timer(lambda: test_data.map(_parse_function))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mdemo_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdemo_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_parse_demo_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0mprint_and_log\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nDone!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   4370\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4371\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4372\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4374\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'map'"
     ]
    }
   ],
   "source": [
    "# # Vectors of filenames.\n",
    "# d_f = []\n",
    "# for i in range(1, 1 + len(CHANNELS)):\n",
    "#     channel = CHANNELS[i-1]\n",
    "#     l = \"Path{}\".format(channel)\n",
    "# #     t_f.append(tf.constant(train_data[l]))\n",
    "# #     v_f.append(tf.constant(validation_data[l]))\n",
    "# #     s_f.append(tf.constant(test_data[l]))\n",
    "#     d_f.append(tf.constant(demo_data))\n",
    "\n",
    "# `labels[i]` is the label for the image in `filenames[i]\n",
    "# Vectors of labels\n",
    "# train_labels = tf.constant(train_labels)\n",
    "# validation_labels = tf.constant(validation_labels)\n",
    "# test_labels = tf.constant(test_labels)\n",
    "\n",
    "# Make datasets from filenames and labels\n",
    "# train_data = tf.data.Dataset.from_tensor_slices((train_labels, *t_f))\n",
    "# validation_data = tf.data.Dataset.from_tensor_slices((validation_labels, *v_f))\n",
    "# test_data = tf.data.Dataset.from_tensor_slices((test_labels, *s_f))\n",
    "print(demo_data)\n",
    "print_and_log_header(\"Parsing Training Data\")\n",
    "# train_data = timer(lambda: train_data.map(_parse_function))\n",
    "# print_and_log_header(\"Parsing Validation Data\")\n",
    "# validation_data = timer(lambda: validation_data.map(_parse_function))\n",
    "# print_and_log_header(\"Parsing Testing Data\")\n",
    "# test_data = timer(lambda: test_data.map(_parse_function))\n",
    "demo_data = timer(lambda: demo_data.map(_parse_demo_function))\n",
    "print_and_log(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########################################\n",
      "                 TRAINING                 \n",
      "##########################################\n",
      "<MapDataset shapes: ((1, 28, 28, 1), ()), types: (tf.float32, tf.int64)>\n",
      "<class 'tensorflow.python.data.ops.dataset_ops.MapDataset'>\n",
      "##########################################\n",
      "                VALIDATION                \n",
      "##########################################\n",
      "<MapDataset shapes: ((1, 28, 28, 1), ()), types: (tf.float32, tf.int64)>\n",
      "<class 'tensorflow.python.data.ops.dataset_ops.MapDataset'>\n",
      "##########################################\n",
      "                 TESTING                  \n",
      "##########################################\n",
      "<MapDataset shapes: ((1, 28, 28, 1), ()), types: (tf.float32, tf.int64)>\n",
      "<class 'tensorflow.python.data.ops.dataset_ops.MapDataset'>\n"
     ]
    }
   ],
   "source": [
    "print_and_log_header(\"TRAINING\")\n",
    "print_and_log(train_data)\n",
    "print_and_log(type(train_data))\n",
    "print_and_log_header(\"VALIDATION\")\n",
    "print_and_log(validation_data)\n",
    "print_and_log(type(validation_data))\n",
    "print_and_log_header(\"TESTING\")\n",
    "print_and_log(test_data)\n",
    "print_and_log(type(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the Estimator\n",
    "if TPU:\n",
    "    classifier = tf.contrib.tpu.TPUEstimator(\n",
    "        model_fn=model_fn,\n",
    "        model_dir=paths[\"Model\"],\n",
    "        config=tf.contrib.tpu.RunConfig(),\n",
    "        use_tpu=TPU)\n",
    "else:\n",
    "    classifier = tf.estimator.Estimator(model_fn=model_fn, model_dir=paths[\"Model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the input functions.\n",
    "demo_eval_input_fn = create_predict_input_fn(demo_data, DEFAULT_BS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_stats = classifier.predict(\n",
    "    input_fn=demo_eval_input_fn, \n",
    "    batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = demo_stats['classes']\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########################################\n",
      "                 TESTING                  \n",
      "##########################################\n",
      "\tLog Loss: 0.68\n",
      "\tAccuracy: 60.47%\n"
     ]
    }
   ],
   "source": [
    "test_stats = classifier.evaluate(input_fn=test_eval_input_fn)\n",
    "t_ll = test_stats[\"loss\"]\n",
    "t_acc = 100 * test_stats[\"accuracy\"]\n",
    "print_and_log_header(\"TESTING\")\n",
    "print_and_log(\"\\tLog Loss: {:.2f}\".format(t_ll))\n",
    "print_and_log(\"\\tAccuracy: {:.2f}%\".format(t_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
