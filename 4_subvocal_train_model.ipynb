{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\n",
      "compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import IPython.display as ipd\n",
    "import random\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as py\n",
    "from IPython import display\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import subprocess\n",
    "from sklearn import metrics\n",
    "%matplotlib inline\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "# NOTES\n",
    "NOTES = \"28x28\"\n",
    "\n",
    "# VARS\n",
    "INPUT_CSV = \"keepers_01_01_1234\"\n",
    "CATEGORY = [\"no_voice\"]\n",
    "ALL_LABELS = ['zero', 'one', 'two', 'three', 'four', \n",
    "            'five', 'six', 'seven', 'eight', 'nine',\n",
    "            'left', 'right', 'stop', 'go', 'up','down']\n",
    "LABELS = ALL_LABELS[:] # choose labels to train on\n",
    "CHANNELS = [1,2,3,4]\n",
    "NUMS = ''.join([str(x) for x in CHANNELS])\n",
    "MONTHS = list(range(1,13))\n",
    "DAYS = list(range(1,32))\n",
    "\n",
    "target_label = \"Label\"\n",
    "id_label = \"fname\"\n",
    "OUTSTR = \"A{:.4f}_Type{}_UDR{}_THRESH{:5.3f}_DROP{}_LR{}_S{}_B{}{}.csv\"\n",
    "IMG_EXT = \".png\"\n",
    "VERBOSE = True\n",
    "DISPLAY = True\n",
    "TEST = False\n",
    "MFCC = False\n",
    "TPU = False\n",
    "RESIZE = True\n",
    "INPUT_WIDTH = 128\n",
    "INPUT_HEIGHT = 128\n",
    "TARGET_WIDTH = 28 if RESIZE else INPUT_WIDTH\n",
    "TARGET_HEIGHT = 28 if RESIZE else INPUT_HEIGHT\n",
    "DECAY_RATE = 0.9\n",
    "IMG_CHANNELS = 3\n",
    "DROPOUT = 0.4\n",
    "TYPE = \"CNN\"\n",
    "DEFAULT_BS = 128 # default batch size\n",
    "UNK_DROP_RATE = 1.0 # drop 100% of unknown categories\n",
    "\n",
    "if TEST:\n",
    "    LEARNING_STEPS = 100\n",
    "    SPP = 4\n",
    "    LEARNING_RATE = .05\n",
    "    BATCH_SIZE = 32\n",
    "    VERBOSITY = 1000\n",
    "    TEST_SIZE = 1000\n",
    "    SHUFFLE_SIZE = 64\n",
    "else:\n",
    "    LEARNING_STEPS = 10000\n",
    "    SPP = 200\n",
    "    LEARNING_RATE = .2 # 0.025 for 2 labels\n",
    "    BATCH_SIZE = 128\n",
    "    VERBOSITY = 1000\n",
    "    SHUFFLE_SIZE = 256\n",
    "\n",
    "def curr_time():\n",
    "    return datetime.now() - timedelta(hours=7) # offset from UTC to PST\n",
    "\n",
    "ROOT = os.getcwd() + \"/\"\n",
    "if CATEGORY[0] == \"no_voice\":\n",
    "    RUN_ROOT = ROOT+\"models/\"+\"NONVOCAL_RUNS_YN_{:02}_{:02}/\".format(MONTHS[0], DAYS[0])\n",
    "else:\n",
    "    RUN_ROOT = ROOT + \"models/\" + \"VOCAL_RUNS_YN_{:02}_{:02}/\".format(MONTHS[0], DAYS[0])\n",
    "RUN_ROOT_LOG = RUN_ROOT + \"logs/\"\n",
    "\n",
    "# PATHS\n",
    "paths = {\n",
    "    \"Training\":ROOT + \"train_csv/\" + INPUT_CSV + \".csv\",\n",
    "    \"Model\":RUN_ROOT+\"model_dir_{}/\".format(NUMS),\n",
    "    \"Logs\":RUN_ROOT_LOG+\"{}_{}/\".format(NUMS, datetime.strftime(curr_time(), \"%b%d%Y_%H%M%S\"))\n",
    "}\n",
    "paths[\"Log\"] = paths[\"Logs\"] + \"log.txt\"\n",
    "if not os.path.isdir(RUN_ROOT):\n",
    "    os.mkdir(RUN_ROOT)\n",
    "if not os.path.isdir(RUN_ROOT_LOG):\n",
    "    os.mkdir(RUN_ROOT_LOG)\n",
    "if not os.path.isdir(paths[\"Logs\"]):\n",
    "    os.mkdir(paths[\"Logs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_header(s):\n",
    "    return (\"#\" * 42) + (\"\\n{:^42}\\n\".format(s)) + (\"#\" * 42)\n",
    "    \n",
    "def print_and_log(s):\n",
    "    with open(paths[\"Log\"], 'a') as log:\n",
    "        log.write(str(s))\n",
    "        log.write(\"\\n\")\n",
    "    print(s)\n",
    "        \n",
    "def print_and_log_header(s):\n",
    "    h = make_header(str(s))\n",
    "    with open(paths[\"Log\"], 'a') as log:\n",
    "        log.write(h)\n",
    "        log.write(\"\\n\")\n",
    "    print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sec_to_str(secs):\n",
    "    ms = secs - int(secs)\n",
    "    days = int(secs // (24 * 3600))\n",
    "    hours = int((secs % ((24 * 3600))) // 3600)\n",
    "    minutes = int((secs % 3600) // 60)\n",
    "    seconds = int(secs % 60)\n",
    "    return \"{:02}:{:02}:{:02}:{:02}.{}\".format(days, hours, minutes, seconds, \"{:.3}\".format(ms)[2:])\n",
    "\n",
    "def timer(f, *args):\n",
    "    print_and_log(\"Start: {}\".format(curr_time()))\n",
    "    start = time.time()\n",
    "    result = f(*args)\n",
    "    end = time.time()\n",
    "    print_and_log(\"End: {}\".format(curr_time()))\n",
    "    print_and_log(\"Finished in {}\".format(sec_to_str(end - start)))\n",
    "    return result\n",
    "\n",
    "def preprocess(samples, sample_rate):\n",
    "    padded = np.zeros(sample_rate)\n",
    "    samples = samples[:sample_rate]\n",
    "    padded[:samples.shape[0]] = samples\n",
    "    return padded\n",
    "\n",
    "def select_labels(df, allowed):\n",
    "    return df[df['Label'].isin(allowed)]\n",
    "    \n",
    "def select_categories(df, allowed):\n",
    "    return df[df['Category'].isin(allowed)]\n",
    "\n",
    "def select_channels(df, allowed):\n",
    "    labels = []\n",
    "    for i in range(1, 9):\n",
    "        if i not in allowed:\n",
    "            labels.append(\"Path{}\".format(i))\n",
    "    return df.drop(labels, axis=1)\n",
    "\n",
    "def select_days(df, allowed):\n",
    "    return df[df['Day'].isin(allowed)]\n",
    "\n",
    "def select_months(df, allowed):\n",
    "    return df[df['Month'].isin(allowed)]\n",
    "\n",
    "def select_sets(df, allowed):\n",
    "    return df[df['Set'].isin(allowed)]\n",
    "\n",
    "def remove_voice(df):\n",
    "    return df.drop([\"Path4\"], axis=1)\n",
    "\n",
    "def str_to_l(x):\n",
    "    return [int(n) for n in x if n <= '9' and n >= '0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "def _parse_function(label, *filenames):\n",
    "    global count\n",
    "    count += 1\n",
    "    if count % VERBOSITY == 0:\n",
    "        print_and_log(\"\\tProcessed {}th image\".format(count))\n",
    "    expected_shape = tf.constant([1, INPUT_HEIGHT, INPUT_WIDTH, IMG_CHANNELS])\n",
    "    image = None\n",
    "    for filename in filenames:\n",
    "        image_string = tf.read_file(filename)\n",
    "        image_decoded = tf.image.decode_image(image_string, channels=IMG_CHANNELS)\n",
    "        image_decoded = tf.image.convert_image_dtype(image_decoded, tf.float32)\n",
    "        image_decoded = tf.reshape(image_decoded, expected_shape)\n",
    "        image_decoded = tf.image.rgb_to_grayscale(image_decoded)\n",
    "        if RESIZE:\n",
    "            image_decoded = tf.image.resize_bicubic(image_decoded, [TARGET_HEIGHT, TARGET_WIDTH])\n",
    "        if image is not None:\n",
    "            image = tf.concat([image, image_decoded], 3)\n",
    "        else:\n",
    "            image = image_decoded\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode):\n",
    "    input_layer = tf.reshape(features, [-1, TARGET_HEIGHT, TARGET_WIDTH, len(CHANNELS)])\n",
    "    pool = input_layer\n",
    "\n",
    "    for num_filters in [32, 64]:\n",
    "        conv = tf.layers.conv2d(\n",
    "            inputs=pool,\n",
    "            filters=num_filters,\n",
    "            kernel_size=[5, 5],\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu)\n",
    "        pool = tf.layers.max_pooling2d(inputs=conv, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    # Dense Layer\n",
    "    pool = tf.layers.flatten(pool)\n",
    "    dense = tf.layers.dense(inputs=pool, units=1024, activation=tf.nn.relu)\n",
    "    dropout = tf.layers.dropout(inputs=dense, rate=DROPOUT, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "    # Logits Layer\n",
    "    logits = tf.layers.dense(inputs=dropout, units=num_labels)\n",
    "    \n",
    "    predictions = {\n",
    "        \"classes\": tf.argmax(input=logits, axis=1),\n",
    "        \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "    }\n",
    "    if not TPU:\n",
    "        tf.summary.histogram(\"predictions\", predictions[\"probabilities\"])\n",
    "        tf.summary.histogram(\"classes\", predictions[\"classes\"])\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "    learning_rate = tf.train.exponential_decay(LEARNING_RATE, tf.train.get_global_step(), SPP, DECAY_RATE, staircase=True)\n",
    "    \n",
    "    # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "    predictions[\"loss\"] = loss\n",
    "    \n",
    "    # Configure the Training Op (for TRAIN mode)\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "        if TPU:\n",
    "            optimizer = tf.contrib.tpu.CrossShardOptimizer(optimizer)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "    # Add evaluation metrics (for EVAL mode)\n",
    "    eval_metric_ops = {\n",
    "        \"accuracy\": tf.metrics.accuracy(\n",
    "            labels=labels, predictions=predictions[\"classes\"])}\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_training_input_fn(dataset, batch_size, num_epochs=None):\n",
    "    def _input_fn(num_epochs=None, shuffle=True):\n",
    "        ds = dataset.batch(batch_size).repeat(num_epochs)\n",
    "        if shuffle:\n",
    "            ds = ds.shuffle(SHUFFLE_SIZE)\n",
    "        feature_batch, label_batch = ds.make_one_shot_iterator().get_next()\n",
    "        return feature_batch, label_batch\n",
    "    return _input_fn\n",
    "\n",
    "def create_predict_input_fn(dataset, batch_size):\n",
    "    def _input_fn():\n",
    "        ds = dataset.batch(batch_size)\n",
    "        feature_batch, label_batch = ds.make_one_shot_iterator().get_next()\n",
    "        return feature_batch, label_batch\n",
    "    return _input_fn\n",
    "\n",
    "def train_helper(steps_per_period):\n",
    "    classifier.train(\n",
    "        input_fn=train_input_fn,\n",
    "        steps=steps_per_period)\n",
    "    training_stats = classifier.evaluate(input_fn=training_eval_input_fn)\n",
    "    validation_stats = classifier.evaluate(input_fn=validation_eval_input_fn)\n",
    "    t_ll = training_stats[\"loss\"]\n",
    "    t_acc = 100 * training_stats[\"accuracy\"]\n",
    "    v_ll = validation_stats[\"loss\"]\n",
    "    v_acc = 100 * validation_stats[\"accuracy\"]\n",
    "    return classifier, t_ll, v_ll, t_acc, v_acc\n",
    "\n",
    "def train():\n",
    "    periods = LEARNING_STEPS // SPP\n",
    "    steps_per_period = LEARNING_STEPS // periods\n",
    "    t_accs, v_accs = [], []\n",
    "    t_lls, v_lls = [], []\n",
    "    print_and_log(\"Training model...\\nMetrics:\")\n",
    "    print_and_log(\"\\tPERIOD\\tRATE\\tTYPE\\tTRAIN.\\tVALID.\\tTIME\")\n",
    "    for period in range(periods):\n",
    "        lr = LEARNING_RATE * (DECAY_RATE ** ((period * SPP) / SPP))\n",
    "        classifier, t_ll, v_ll, t_acc, v_acc = train_helper(steps_per_period)\n",
    "        print_and_log(\"\\t{}\\t{:.5f}\\tLgLs\\t{:.2f}\\t{:.2f}\\t{}\".format(period, lr, t_ll, v_ll, curr_time()))\n",
    "        print_and_log(\"\\t\\t\\tAcc.\\t{:.2f}%\\t{:.2f}%\\n\".format(t_acc, v_acc))\n",
    "        t_lls.append(t_ll)\n",
    "        v_lls.append(v_ll)\n",
    "        t_accs.append(t_acc)\n",
    "        v_accs.append(v_acc)\n",
    "    v_accuracy = v_accs[-1]\n",
    "    return classifier, v_accuracy, t_lls, v_lls, t_accs, v_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(paths[\"Log\"], 'w') as log:\n",
    "    log.write(make_header(\"Starting Script\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create variables for the paths\n",
    "train_csv = paths[\"Training\"]\n",
    "\n",
    "# Store the labels to train\n",
    "all_labels = LABELS\n",
    "labels = LABELS\n",
    "num_labels = len(labels)# - 1\n",
    "labels = {x[1]:x[0] for x in enumerate(labels)}\n",
    "reverse_lookup = {labels[k]:k for k in labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'zero', 1: 'one', 2: 'two', 3: 'three', 4: 'four', 5: 'five', 6: 'six', 7: 'seven', 8: 'eight', 9: 'nine', 10: 'left', 11: 'right', 12: 'stop', 13: 'go', 14: 'up', 15: 'down'}\n"
     ]
    }
   ],
   "source": [
    "print(reverse_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########################################\n",
      "           MAKING TRAINING DATA           \n",
      "##########################################\n",
      "##########################################\n",
      "                TRAIN DATA                \n",
      "##########################################\n",
      "         Unnamed: 0           Day         Month         Label  SequenceNumber\n",
      "count  10917.000000  10917.000000  10917.000000  10917.000000    10917.000000\n",
      "mean    5458.000000     16.173491      6.377576      7.391591       31.575799\n",
      "std     3151.610779     12.143952      5.498889      4.623246       18.176833\n",
      "min        0.000000      2.000000      1.000000      0.000000        0.000000\n",
      "25%     2729.000000      4.000000      1.000000      3.000000       16.000000\n",
      "50%     5458.000000      7.000000      1.000000      7.000000       32.000000\n",
      "75%     8187.000000     28.000000     12.000000     11.000000       47.000000\n",
      "max    10916.000000     31.000000     12.000000     15.000000       64.000000\n",
      "   Unnamed: 0  Category  Day  Month  Label  SequenceNumber       Set  \\\n",
      "0        1678  no_voice   28     12     10              41  Training   \n",
      "1        8962  no_voice    4      1      1               0  Training   \n",
      "2        5525  no_voice    6      1      5               2  Training   \n",
      "3       10032  no_voice    2      1      2              31  Training   \n",
      "4       10265  no_voice   27     12      1              37  Training   \n",
      "5        2993  no_voice    7      1      3               6  Training   \n",
      "6          72  no_voice   26     12     15              23  Training   \n",
      "7        8872  no_voice   30     12      1              50  Training   \n",
      "8         463  no_voice   27     12      7              30  Training   \n",
      "9        1485  no_voice   27     12     14              21  Training   \n",
      "\n",
      "                                               Path1  \\\n",
      "0  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "1  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "2  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "3  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "4  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "5  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "6  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "7  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "8  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "9  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "\n",
      "                                               Path2  \\\n",
      "0  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "1  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "2  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "3  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "4  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "5  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "6  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "7  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "8  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "9  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "\n",
      "                                               Path3  \\\n",
      "0  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "1  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "2  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "3  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "4  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "5  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "6  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "7  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "8  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "9  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "\n",
      "                                               Path4  \n",
      "0  /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "1  /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "2  /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "3  /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "4  /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "5  /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "6  /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "7  /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "8  /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "9  /Users/kyy/cerebro_train/images_scaled/subvoca...  \n"
     ]
    }
   ],
   "source": [
    "# Make the training data\n",
    "print_and_log_header(\"MAKING TRAINING DATA\")\n",
    "train_data = pd.read_csv(train_csv)\n",
    "\n",
    "# Filter the training data\n",
    "train_data = select_categories(train_data, CATEGORY)\n",
    "#train_data = select_channels(train_data, CHANNELS)\n",
    "train_data = select_labels(train_data, all_labels)\n",
    "train_data = select_months(train_data, MONTHS)\n",
    "train_data = select_days(train_data, DAYS)\n",
    "# train_data = remove_voice(train_data)\n",
    "\n",
    "train_data = train_data.sample(frac=1).reset_index(drop=True)\n",
    "train_data[\"Label\"] = train_data[\"Label\"].map(labels)\n",
    "\n",
    "if VERBOSE:\n",
    "    print_and_log_header(\"TRAIN DATA\")\n",
    "    print_and_log(train_data.describe())\n",
    "    print_and_log(train_data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  Category  Day  Month  Label  SequenceNumber       Set  \\\n",
      "0        1678  no_voice   28     12     10              41  Training   \n",
      "1        8962  no_voice    4      1      1               0  Training   \n",
      "2        5525  no_voice    6      1      5               2  Training   \n",
      "3       10032  no_voice    2      1      2              31  Training   \n",
      "4       10265  no_voice   27     12      1              37  Training   \n",
      "5        2993  no_voice    7      1      3               6  Training   \n",
      "6          72  no_voice   26     12     15              23  Training   \n",
      "7        8872  no_voice   30     12      1              50  Training   \n",
      "8         463  no_voice   27     12      7              30  Training   \n",
      "9        1485  no_voice   27     12     14              21  Training   \n",
      "\n",
      "                                               Path1  \\\n",
      "0  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "1  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "2  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "3  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "4  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "5  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "6  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "7  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "8  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "9  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "\n",
      "                                               Path2  \\\n",
      "0  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "1  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "2  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "3  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "4  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "5  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "6  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "7  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "8  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "9  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "\n",
      "                                               Path3  \\\n",
      "0  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "1  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "2  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "3  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "4  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "5  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "6  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "7  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "8  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "9  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "\n",
      "                                               Path4  \n",
      "0  /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "1  /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "2  /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "3  /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "4  /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "5  /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "6  /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "7  /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "8  /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "9  /Users/kyy/cerebro_train/images_scaled/subvoca...  \n"
     ]
    }
   ],
   "source": [
    "if VERBOSE:\n",
    "    print_and_log(train_data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Grab subset of the data for testing purposes\n",
    "if TEST:\n",
    "    train_data = train_data[:TEST_SIZE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 80/10/10 training/validation/test split\n",
    "validation_data = select_sets(train_data, [\"Validation\"])\n",
    "test_data = select_sets(train_data, [\"Testing\"])\n",
    "train_data = select_sets(train_data, [\"Training\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0  Category  Day  Month  Label  SequenceNumber       Set  \\\n",
      "0            1678  no_voice   28     12     10              41  Training   \n",
      "1            8962  no_voice    4      1      1               0  Training   \n",
      "2            5525  no_voice    6      1      5               2  Training   \n",
      "3           10032  no_voice    2      1      2              31  Training   \n",
      "4           10265  no_voice   27     12      1              37  Training   \n",
      "5            2993  no_voice    7      1      3               6  Training   \n",
      "6              72  no_voice   26     12     15              23  Training   \n",
      "7            8872  no_voice   30     12      1              50  Training   \n",
      "8             463  no_voice   27     12      7              30  Training   \n",
      "9            1485  no_voice   27     12     14              21  Training   \n",
      "10           7626  no_voice    3      1     10              61  Training   \n",
      "11           1925  no_voice    6      1      1               0  Training   \n",
      "12           2840  no_voice    6      1      4              45  Training   \n",
      "14              5  no_voice   27     12      0               0  Training   \n",
      "15           2693  no_voice   28     12      1              26  Training   \n",
      "16           7732  no_voice   28     12      2              34  Training   \n",
      "18          10176  no_voice   27     12      7              27  Training   \n",
      "19           4771  no_voice   27     12     11              53  Training   \n",
      "20           2981  no_voice   29     12      4               5  Training   \n",
      "21           3793  no_voice    7      1     12              55  Training   \n",
      "22           8699  no_voice    6      1      1              52  Training   \n",
      "23           8827  no_voice    4      1      2              20  Training   \n",
      "24           8665  no_voice   26     12      2              30  Training   \n",
      "25           3770  no_voice    3      1     15              52  Training   \n",
      "26           2979  no_voice   31     12     10              37  Training   \n",
      "28           4238  no_voice    6      1      6              27  Training   \n",
      "29           9269  no_voice   28     12      4              61  Training   \n",
      "30           1893  no_voice    6      1      1              44  Training   \n",
      "32           3420  no_voice   31     12      0              47  Training   \n",
      "33           7291  no_voice   31     12      2              40  Training   \n",
      "...           ...       ...  ...    ...    ...             ...       ...   \n",
      "10874        2083  no_voice    2      1      7              56  Training   \n",
      "10875        5935  no_voice   26     12     15              41  Training   \n",
      "10876        5385  no_voice   30     12      0              40  Training   \n",
      "10879        6775  no_voice   26     12      9              55  Training   \n",
      "10883        1886  no_voice   28     12      5              24  Training   \n",
      "10884        5701  no_voice   30     12      5              61  Training   \n",
      "10885        5337  no_voice    7      1     10              13  Training   \n",
      "10886         729  no_voice    5      1      9              37  Training   \n",
      "10887        2040  no_voice    4      1      7              11  Training   \n",
      "10888        8524  no_voice   26     12     13              26  Training   \n",
      "10889        6809  no_voice   27     12     13              15  Training   \n",
      "10890        4556  no_voice    2      1      3               3  Training   \n",
      "10891        1615  no_voice    2      1     13              54  Training   \n",
      "10892        8231  no_voice   28     12      9              25  Training   \n",
      "10895        4580  no_voice    6      1     11              60  Training   \n",
      "10898        9047  no_voice    2      1      3              37  Training   \n",
      "10899        2666  no_voice   31     12      5              36  Training   \n",
      "10901        2292  no_voice   29     12      1              61  Training   \n",
      "10902        8977  no_voice    4      1      5              51  Training   \n",
      "10903        5581  no_voice    4      1      8              24  Training   \n",
      "10904        5114  no_voice   31     12     15              41  Training   \n",
      "10906        4950  no_voice    2      1     15              13  Training   \n",
      "10907        9348  no_voice   28     12     13               2  Training   \n",
      "10908          96  no_voice   31     12     10              34  Training   \n",
      "10909        8985  no_voice    7      1      2              47  Training   \n",
      "10911        5484  no_voice   26     12      1              16  Training   \n",
      "10912       10311  no_voice   27     12      3              41  Training   \n",
      "10913        9546  no_voice    4      1      6              42  Training   \n",
      "10914        5175  no_voice    3      1      3              13  Training   \n",
      "10916        7287  no_voice   27     12      5               1  Training   \n",
      "\n",
      "                                                   Path1  \\\n",
      "0      /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "1      /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "2      /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "3      /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "4      /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "5      /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "6      /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "7      /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "8      /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "9      /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10     /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "11     /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "12     /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "14     /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "15     /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "16     /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "18     /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "19     /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "20     /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "21     /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "22     /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "23     /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "24     /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "25     /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "26     /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "28     /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "29     /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "30     /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "32     /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "33     /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "...                                                  ...   \n",
      "10874  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10875  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10876  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10879  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10883  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10884  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10885  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10886  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10887  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10888  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10889  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10890  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10891  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10892  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10895  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10898  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10899  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10901  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10902  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10903  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10904  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10906  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10907  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10908  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10909  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10911  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10912  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10913  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10914  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10916  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "\n",
      "                                                   Path2  \\\n",
      "0      /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "1      /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "2      /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "3      /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "4      /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "5      /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "6      /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "7      /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "8      /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "9      /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10     /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "11     /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "12     /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "14     /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "15     /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "16     /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "18     /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "19     /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "20     /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "21     /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "22     /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "23     /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "24     /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "25     /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "26     /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "28     /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "29     /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "30     /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "32     /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "33     /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "...                                                  ...   \n",
      "10874  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10875  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10876  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10879  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10883  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10884  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10885  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10886  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10887  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10888  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10889  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10890  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10891  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10892  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10895  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10898  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10899  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10901  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10902  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10903  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10904  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10906  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10907  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10908  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10909  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10911  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10912  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10913  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10914  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10916  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "\n",
      "                                                   Path3  \\\n",
      "0      /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "1      /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "2      /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "3      /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "4      /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "5      /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "6      /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "7      /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "8      /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "9      /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10     /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "11     /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "12     /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "14     /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "15     /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "16     /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "18     /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "19     /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "20     /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "21     /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "22     /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "23     /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "24     /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "25     /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "26     /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "28     /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "29     /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "30     /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "32     /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "33     /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "...                                                  ...   \n",
      "10874  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10875  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10876  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10879  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10883  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10884  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10885  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10886  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10887  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10888  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10889  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10890  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10891  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10892  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10895  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10898  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10899  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10901  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10902  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10903  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10904  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10906  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10907  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10908  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10909  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10911  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10912  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10913  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10914  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "10916  /Users/kyy/cerebro_train/images_scaled/subvoca...   \n",
      "\n",
      "                                                   Path4  \n",
      "0      /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "1      /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "2      /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "3      /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "4      /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "5      /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "6      /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "7      /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "8      /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "9      /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "10     /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "11     /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "12     /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "14     /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "15     /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "16     /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "18     /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "19     /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "20     /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "21     /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "22     /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "23     /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "24     /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "25     /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "26     /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "28     /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "29     /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "30     /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "32     /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "33     /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "...                                                  ...  \n",
      "10874  /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "10875  /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "10876  /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "10879  /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "10883  /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "10884  /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "10885  /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "10886  /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "10887  /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "10888  /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "10889  /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "10890  /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "10891  /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "10892  /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "10895  /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "10898  /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "10899  /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "10901  /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "10902  /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "10903  /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "10904  /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "10906  /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "10907  /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "10908  /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "10909  /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "10911  /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "10912  /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "10913  /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "10914  /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "10916  /Users/kyy/cerebro_train/images_scaled/subvoca...  \n",
      "\n",
      "[8833 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########################################\n",
      "                   IDS                    \n",
      "##########################################\n",
      "count                                                  1036\n",
      "unique                                                 1036\n",
      "top       /Users/kyy/cerebro_train/images_scaled/subvoca...\n",
      "freq                                                      1\n",
      "Name: Path1, dtype: object\n",
      "13    /Users/kyy/cerebro_train/images_scaled/subvoca...\n",
      "31    /Users/kyy/cerebro_train/images_scaled/subvoca...\n",
      "38    /Users/kyy/cerebro_train/images_scaled/subvoca...\n",
      "40    /Users/kyy/cerebro_train/images_scaled/subvoca...\n",
      "43    /Users/kyy/cerebro_train/images_scaled/subvoca...\n",
      "47    /Users/kyy/cerebro_train/images_scaled/subvoca...\n",
      "57    /Users/kyy/cerebro_train/images_scaled/subvoca...\n",
      "63    /Users/kyy/cerebro_train/images_scaled/subvoca...\n",
      "69    /Users/kyy/cerebro_train/images_scaled/subvoca...\n",
      "76    /Users/kyy/cerebro_train/images_scaled/subvoca...\n",
      "Name: Path1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "ids = test_data[\"Path{}\".format(CHANNELS[0])] # store the png filenames for output\n",
    "if VERBOSE:\n",
    "    print_and_log_header(\"IDS\")\n",
    "    print_and_log(ids.describe())\n",
    "    print_and_log(ids.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Separate Labels\n",
    "train_labels = train_data.pop(target_label)\n",
    "validation_labels = validation_data.pop(target_label)\n",
    "l_test_labels = test_data.pop(target_label)\n",
    "img_paths = [\"Path{}\".format(channel) for channel in CHANNELS]\n",
    "train_data = train_data[img_paths]\n",
    "validation_data = validation_data[img_paths]\n",
    "test_data = test_data[img_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########################################\n",
      "          Parsing Training Data           \n",
      "##########################################\n",
      "Start: 2019-01-06 08:46:38.569938\n",
      "End: 2019-01-06 08:46:38.864513\n",
      "Finished in 00:00:00:00.288\n",
      "##########################################\n",
      "         Parsing Validation Data          \n",
      "##########################################\n",
      "Start: 2019-01-06 08:46:38.871232\n",
      "End: 2019-01-06 08:46:39.096562\n",
      "Finished in 00:00:00:00.225\n",
      "##########################################\n",
      "           Parsing Testing Data           \n",
      "##########################################\n",
      "Start: 2019-01-06 08:46:39.103991\n",
      "End: 2019-01-06 08:46:39.334254\n",
      "Finished in 00:00:00:00.229\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Vectors of filenames.\n",
    "t_f, v_f, s_f = [], [], []\n",
    "for i in range(1, 1 + len(CHANNELS)):\n",
    "    channel = CHANNELS[i-1]\n",
    "    l = \"Path{}\".format(channel)\n",
    "    t_f.append(tf.constant(train_data[l]))\n",
    "    v_f.append(tf.constant(validation_data[l]))\n",
    "    s_f.append(tf.constant(test_data[l]))\n",
    "\n",
    "# `labels[i]` is the label for the image in `filenames[i]\n",
    "# Vectors of labels\n",
    "train_labels = tf.constant(train_labels)\n",
    "validation_labels = tf.constant(validation_labels)\n",
    "test_labels = tf.constant(l_test_labels)\n",
    "\n",
    "# Make datasets from filenames and labels\n",
    "train_data = tf.data.Dataset.from_tensor_slices((train_labels, *t_f))\n",
    "validation_data = tf.data.Dataset.from_tensor_slices((validation_labels, *v_f))\n",
    "test_data = tf.data.Dataset.from_tensor_slices((test_labels, *s_f))\n",
    "print_and_log_header(\"Parsing Training Data\")\n",
    "train_data = timer(lambda: train_data.map(_parse_function))\n",
    "print_and_log_header(\"Parsing Validation Data\")\n",
    "validation_data = timer(lambda: validation_data.map(_parse_function))\n",
    "print_and_log_header(\"Parsing Testing Data\")\n",
    "test_data = timer(lambda: test_data.map(_parse_function))\n",
    "print_and_log(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########################################\n",
      "                 TRAINING                 \n",
      "##########################################\n",
      "<MapDataset shapes: ((1, 28, 28, 4), ()), types: (tf.float32, tf.int64)>\n",
      "<class 'tensorflow.python.data.ops.dataset_ops.MapDataset'>\n",
      "##########################################\n",
      "                VALIDATION                \n",
      "##########################################\n",
      "<MapDataset shapes: ((1, 28, 28, 4), ()), types: (tf.float32, tf.int64)>\n",
      "<class 'tensorflow.python.data.ops.dataset_ops.MapDataset'>\n",
      "##########################################\n",
      "                 TESTING                  \n",
      "##########################################\n",
      "<MapDataset shapes: ((1, 28, 28, 4), ()), types: (tf.float32, tf.int64)>\n",
      "<class 'tensorflow.python.data.ops.dataset_ops.MapDataset'>\n"
     ]
    }
   ],
   "source": [
    "print_and_log_header(\"TRAINING\")\n",
    "print_and_log(train_data)\n",
    "print_and_log(type(train_data))\n",
    "print_and_log_header(\"VALIDATION\")\n",
    "print_and_log(validation_data)\n",
    "print_and_log(type(validation_data))\n",
    "print_and_log_header(\"TESTING\")\n",
    "print_and_log(test_data)\n",
    "print_and_log(type(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the Estimator\n",
    "if TPU:\n",
    "    classifier = tf.contrib.tpu.TPUEstimator(\n",
    "        model_fn=model_fn,\n",
    "        model_dir=paths[\"Model\"],\n",
    "        config=tf.contrib.tpu.RunConfig(),\n",
    "        use_tpu=TPU)\n",
    "else:\n",
    "    classifier = tf.estimator.Estimator(model_fn=model_fn, model_dir=paths[\"Model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the input functions.\n",
    "training_eval_input_fn = create_predict_input_fn(train_data, DEFAULT_BS)\n",
    "validation_eval_input_fn = create_predict_input_fn(validation_data, DEFAULT_BS)\n",
    "test_eval_input_fn = create_predict_input_fn(test_data, DEFAULT_BS)\n",
    "train_input_fn = create_training_input_fn(train_data, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: 2019-01-06 08:46:39.366574\n",
      "Training model...\n",
      "Metrics:\n",
      "\tPERIOD\tRATE\tTYPE\tTRAIN.\tVALID.\tTIME\n",
      "\t0\t0.20000\tLgLs\t2.77\t2.78\t2019-01-06 08:48:31.382325\n",
      "\t\t\tAcc.\t6.49%\t6.49%\n",
      "\n",
      "\t1\t0.18000\tLgLs\t2.77\t2.78\t2019-01-06 08:50:17.657847\n",
      "\t\t\tAcc.\t6.49%\t6.49%\n",
      "\n",
      "\t2\t0.16200\tLgLs\t2.76\t2.77\t2019-01-06 08:52:04.332558\n",
      "\t\t\tAcc.\t8.66%\t8.97%\n",
      "\n",
      "\t3\t0.14580\tLgLs\t2.68\t2.69\t2019-01-06 08:53:50.692497\n",
      "\t\t\tAcc.\t11.05%\t11.74%\n",
      "\n",
      "\t4\t0.13122\tLgLs\t2.71\t2.71\t2019-01-06 08:55:44.677859\n",
      "\t\t\tAcc.\t10.70%\t10.69%\n",
      "\n",
      "\t5\t0.11810\tLgLs\t2.58\t2.60\t2019-01-06 08:57:32.769609\n",
      "\t\t\tAcc.\t17.56%\t17.18%\n",
      "\n",
      "\t6\t0.10629\tLgLs\t2.51\t2.55\t2019-01-06 08:59:22.770067\n",
      "\t\t\tAcc.\t18.50%\t16.51%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "classifier, accuracy, t_lls, v_lls, t_accs, v_accs = timer(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_and_log(\"Final accuracy (on validation data): {:.4f}%\".format(accuracy))\n",
    "\n",
    "if DISPLAY:\n",
    "    # Output a graph of loss metrics over periods.\n",
    "    plt.ylabel(\"LogLoss\")\n",
    "    plt.xlabel(\"Periods\")\n",
    "    plt.title(\"LogLoss vs. Periods\")\n",
    "    plt.plot(t_lls, label=\"training\")\n",
    "    plt.plot(v_lls, label=\"validation\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.savefig(paths[\"Logs\"] + \"loss.png\")\n",
    "\n",
    "    # Output a graph of accuracy over periods.\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.xlabel(\"Periods\")\n",
    "    plt.title(\"Accuracy vs. Periods\")\n",
    "    plt.plot(t_accs, label=\"training\")\n",
    "    plt.plot(v_accs, label=\"validation\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.savefig(paths[\"Logs\"] + \"accuracy.png\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stats = classifier.evaluate(input_fn=test_eval_input_fn)\n",
    "t_ll = test_stats[\"loss\"]\n",
    "t_acc = 100 * test_stats[\"accuracy\"]\n",
    "print_and_log_header(\"TESTING\")\n",
    "print_and_log(\"\\tLog Loss: {:.2f}\".format(t_ll))\n",
    "print_and_log(\"\\tAccuracy: {:.2f}%\".format(t_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [x for x in classifier.predict(input_fn=test_eval_input_fn)]\n",
    "classes = [x[\"classes\"] for x in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output confusion matrix\n",
    "test_labels_list = l_test_labels.tolist()\n",
    "# test_labels_list = {reverse_lookup[k] for k in test_labels_list}\n",
    "# classes = {reverse_lookup[k] for k in classes}\n",
    "\n",
    "cm = metrics.confusion_matrix(test_labels_list, classes)\n",
    "# Normalize the confusion matrix by row (i.e by the number of samples\n",
    "# in each class).\n",
    "cm_normalized = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n",
    "ax = sns.heatmap(cm_normalized, cmap=\"bone_r\")\n",
    "ax.set_aspect(1)\n",
    "ax.set_xticklabels(ALL_LABELS, rotation=45)\n",
    "ax.set_yticklabels(ALL_LABELS, rotation=0)\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.ylabel(\"True label\")\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indices_list = []\n",
    "\n",
    "for i in range(16):\n",
    "    for j in range(16):\n",
    "        if j > i:\n",
    "            indices_list.append([j,i, cm[i][j]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_list = indices_list[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"['predict, 'target']\")\n",
    "for lst in max_list:\n",
    "    print(list(map(reverse_lookup.get, lst[:2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
